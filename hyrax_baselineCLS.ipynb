{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3999bc52-50d5-4ea8-b253-55dd58fee4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyrax import Hyrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304d835-da03-4fae-b0fe-c3e894ee17a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbranton/.virtualenvs/applecider/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "[2025-10-16 16:02:18,613 hyrax.prepare:INFO] Finished Prepare\n"
     ]
    }
   ],
   "source": [
    "#toml_path = \"/Users/dbranton/lincc/incubators/applecider/AppleCider/default_config.toml\"\n",
    "toml_path = \"/Users/dbranton/lincc/incubators/baselineCLS_runtime_config.toml\"\n",
    "h = Hyrax(config_file=toml_path)\n",
    "h.config[\"model_inputs\"] = {\n",
    "    \"data\": {\n",
    "        \"dataset_class\": \"AppleCider.models.hyrax_models.photo_dataset.PhotoEventsDataset\",\n",
    "        \"data_location\": \"/Users/dbranton/lincc/incubators/photo_events/train/\",\n",
    "        \"manifest_path\": \"/Users/dbranton/lincc/incubators/photo_events/manifest_train.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset = h.prepare()\n",
    "#h.config[\"data_set\"][\"name\"] = \"PhotoEventsDataset\"\n",
    "#h.config[\"data_set\"][\"data_location\"] = \"/Users/dbranton/lincc/incubators/photo_events/\"\n",
    "#h = Hyrax()\n",
    "#h.set_config('model.name', 'AppleCider.models.hyrax_models.HyraxBaselineCLS.HyraxBaselineCLS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43569f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h.config[\"data_loader\"][\"batch_size\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81dd5c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-16 16:02:18,963 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining dataset(s):\u001b[0m\n",
      "Name: data\n",
      "  Dataset class: AppleCider.models.hyrax_models.photo_dataset.PhotoEventsDataset\n",
      "  Data location: /Users/dbranton/lincc/incubators/photo_events/train/\n",
      "  Requested fields: photometry\n",
      "\n",
      "[2025-10-16 16:02:18,974 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining model:\u001b[0m\n",
      "HyraxBaselineCLS(\n",
      "  (in_proj): Linear(in_features=7, out_features=128, bias=True)\n",
      "  (time2vec): Time2Vec()\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "2025-10-16 16:02:18,987 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data\n",
      "  Dataset': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x173b33770>, 'batch_size': 3, 'shuffle': False, 'pin_memory': False}\n",
      "2025-10-16 16:02:18,988 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data\n",
      "  Dataset': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x173b337a0>, 'batch_size': 3, 'shuffle': False, 'pin_memory': False}\n",
      "/Users/dbranton/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/handlers/tqdm_logger.py:127: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2025/10/16 16:02:19 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/16 16:02:19 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "Current run is terminating due to exception: stack expects each tensor to be equal size, but got [11] at entry 0 and [150] at entry 1\n",
      "Engine run is terminating due to exception: stack expects each tensor to be equal size, but got [11] at entry 0 and [150] at entry 1\n",
      "2025/10/16 16:02:19 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/16 16:02:19 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11505\n",
      "2887\n",
      "1292\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [11] at entry 0 and [150] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/hyrax/verbs/train.py:97\u001b[39m, in \u001b[36mTrain.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m     Train._log_params(config, results_dir)\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# Run the training process\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[32m    100\u001b[39m model.save(results_dir / config[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mweights_filename\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:905\u001b[39m, in \u001b[36mEngine.run\u001b[39m\u001b[34m(self, data, max_epochs, epoch_length)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.dataloader = data\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.interrupt_resume_enabled:\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_run_legacy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:948\u001b[39m, in \u001b[36mEngine._internal_run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    946\u001b[39m     \u001b[38;5;28mself\u001b[39m._internal_run_generator = \u001b[38;5;28mself\u001b[39m._internal_run_as_gen()\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m._internal_run_generator = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:1023\u001b[39m, in \u001b[36mEngine._internal_run_as_gen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28mself\u001b[39m._dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:660\u001b[39m, in \u001b[36mEngine._handle_exception\u001b[39m\u001b[34m(self, e)\u001b[39m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28mself\u001b[39m._fire_event(Events.EXCEPTION_RAISED, e)\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:972\u001b[39m, in \u001b[36mEngine._internal_run_as_gen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    970\u001b[39m     \u001b[38;5;28mself\u001b[39m._setup_engine()\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m epoch_time_taken += \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_once_on_dataset_as_gen()\n\u001b[32m    974\u001b[39m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[32m    975\u001b[39m \u001b[38;5;28mself\u001b[39m.state.times[Events.EPOCH_COMPLETED.name] = epoch_time_taken\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:1128\u001b[39m, in \u001b[36mEngine._run_once_on_dataset_as_gen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:660\u001b[39m, in \u001b[36mEngine._handle_exception\u001b[39m\u001b[34m(self, e)\u001b[39m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28mself\u001b[39m._fire_event(Events.EXCEPTION_RAISED, e)\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/engine/engine.py:1066\u001b[39m, in \u001b[36mEngine._run_once_on_dataset_as_gen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1063\u001b[39m         \u001b[38;5;28mself\u001b[39m._fire_event(Events.GET_BATCH_STARTED)\n\u001b[32m   1064\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._maybe_terminate_or_interrupt()\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m \u001b[38;5;28mself\u001b[39m.state.batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[38;5;66;03m# We should not trigger GET_BATCH_STARTED, GET_BATCH_COMPLETED, DATALOADER_STOP_ITERATION events\u001b[39;00m\n\u001b[32m   1069\u001b[39m \u001b[38;5;66;03m# if no data was provided to engine.run(data=None, ...)\u001b[39;00m\n\u001b[32m   1070\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:172\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections.abc.MutableMapping):\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[32m    169\u001b[39m     clone = copy.copy(elem)\n\u001b[32m    170\u001b[39m     clone.update(\n\u001b[32m    171\u001b[39m         {\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[32m    176\u001b[39m         }\n\u001b[32m    177\u001b[39m     )\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:172\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections.abc.MutableMapping):\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[32m    169\u001b[39m     clone = copy.copy(elem)\n\u001b[32m    170\u001b[39m     clone.update(\n\u001b[32m    171\u001b[39m         {\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[32m    176\u001b[39m         }\n\u001b[32m    177\u001b[39m     )\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:172\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections.abc.MutableMapping):\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[32m    169\u001b[39m     clone = copy.copy(elem)\n\u001b[32m    170\u001b[39m     clone.update(\n\u001b[32m    171\u001b[39m         {\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[32m    176\u001b[39m         }\n\u001b[32m    177\u001b[39m     )\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:285\u001b[39m, in \u001b[36mcollate_numpy_array_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern.search(elem.dtype.str) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format.format(elem.dtype))\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects each tensor to be equal size, but got [11] at entry 0 and [150] at entry 1"
     ]
    }
   ],
   "source": [
    "h.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12771"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597a23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'dev_mode': False, 'log_destination': 'stderr', 'log_level': 'info', 'data_dir': '/Users/dbranton/lincc/incubators/data', 'results_dir': './results'}, 'download': {'sw': '22asec', 'sh': '22asec', 'filter': ['HSC-G', 'HSC-R', 'HSC-I', 'HSC-Z', 'HSC-Y'], 'type': 'coadd', 'rerun': 'pdr3_wide', 'credentials_file': './credentials.ini', 'username': False, 'password': False, 'num_sources': -1, 'concurrent_connections': 4, 'stats_print_interval': 60, 'fits_file': './catalog.fits', 'retry_wait': 30, 'retries': 3, 'timeout': 3600, 'chunk_size': 990, 'image': True, 'variance': False, 'mask': False}, 'model': {'name': 'AppleCider.models.hyrax_models.HyraxBaselineCLS.HyraxBaselineCLS', 'base_channel_size': 32, 'latent_dim': 64, 'final_layer': 'tanh', 'HyraxCNN': {'output_classes': 10}, 'AstroMiNN': {'num_classes': 5, 'num_mlp_experts': 4, 'towers_hidden_dims': 16, 'towers_outdims': 32, 'fusion_hidden_dims': 128, 'fusion_router_dims': 128, 'fusion_outdims': 32}, 'BaselineCLS': {'num_classes': 5, 'pad_mask': 1, 'mode': 'photo', 'output_dir': '/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events', 'stats_file': 'feature_stats_day100.npz', 'horizon_days': 50.0, 'batch_size': 256, 'sampler_balance': True, 'num_workers': 8, 'd_model': 128, 'n_heads': 8, 'n_layers': 4, 'dropout': 0.3, 'max_len': 257, 'lr': 5e-06, 'weight_decay': 0.01, 'focal_gamma': 2.0, 'cut_time_p': False, 'p_dropout': 0.1, 'jitter_scale': 0.1, 'flux_nu': 8, 'epochs': 150, 'patience': 30, 'seed': 42}}, 'criterion': {'name': 'torch.nn.CrossEntropyLoss', 'band_loss_reduction': 'mean'}, 'optimizer': {'name': 'torch.optim.SGD'}, 'torch.optim.SGD': {'lr': 0.01, 'momentum': 0.9}, 'torch.optim.Adam': {'lr': 0.01}, 'train': {'weights_filename': 'example_model.pth', 'epochs': 10, 'resume': False, 'split': 'train', 'experiment_name': 'notebook', 'run_name': False}, 'onnx': {'opset_version': 20}, 'model_inputs': {'data': {'dataset_class': 'PhotoEventsDataset', 'data_location': './data', 'primary_id_field': 'object_id', 'dataset_config': {'data_location': '/Users/dbranton/lincc/incubators/photo_events/'}}}, 'data_set': {'name': 'HyraxCifarDataSet', 'crop_to': False, 'filters': False, 'filter_catalog': False, 'transform': 'tanh', 'train_size': 0.6, 'validate_size': 0.2, 'test_size': 0.2, 'seed': False, 'use_cache': True, 'preload_cache': True, 'object_id_column_name': False, 'filter_column_name': False, 'filename_column_name': False, 'nan_mode': False, 'nan_quantile': 0.05, 'astropy_table': False, 'semi_width_deg': 0.00472, 'semi_height_deg': 0.00472, 'HyraxRandomDataset': {'size': 100, 'shape': [2, 5, 5], 'seed': 42, 'provided_labels': [0, 1, 2], 'metadata_fields': ['meta_field_1', 'meta_field_2'], 'number_invalid_values': 0, 'invalid_value_type': 'nan'}}, 'data_loader': {'batch_size': 512, 'shuffle': False}, 'infer': {'model_weights_file': False, 'split': False}, 'vector_db': {'name': 'chromadb', 'vector_db_dir': False, 'infer_results_dir': False, 'chromadb': {'shard_size_limit': 65536, 'vector_size_warning': 10000}, 'qdrant': {'vector_size': 64}}, 'results': {'inference_dir': False}, 'umap': {'fit_sample_size': 1024, 'save_fit_umap': True, 'parallel': False, 'name': 'umap.UMAP', 'UMAP': {'n_components': 2, 'n_neighbors': 15}}, 'visualize': {'fields': [], 'display_images': False, 'color_column': False, 'cmap': 'viridis', 'torch_tensor_bands': [3], 'rasterize_plot': False}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15c9c4-7858-4798-83af-74d60f60a095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'dev_mode': False, 'log_destination': 'stderr', 'log_level': 'info', 'data_dir': '/Users/dbranton/lincc/incubators/data', 'results_dir': './results'}, 'download': {'sw': '22asec', 'sh': '22asec', 'filter': ['HSC-G', 'HSC-R', 'HSC-I', 'HSC-Z', 'HSC-Y'], 'type': 'coadd', 'rerun': 'pdr3_wide', 'credentials_file': './credentials.ini', 'username': False, 'password': False, 'num_sources': -1, 'concurrent_connections': 4, 'stats_print_interval': 60, 'fits_file': './catalog.fits', 'retry_wait': 30, 'retries': 3, 'timeout': 3600, 'chunk_size': 990, 'image': True, 'variance': False, 'mask': False}, 'model': {'name': 'AppleCider.models.hyrax_models.HyraxBaselineCLS.HyraxBaselineCLS', 'base_channel_size': 32, 'latent_dim': 64, 'final_layer': 'tanh', 'HyraxCNN': {'output_classes': 10}, 'AstroMiNN': {'num_classes': 5, 'num_mlp_experts': 4, 'towers_hidden_dims': 16, 'towers_outdims': 32, 'fusion_hidden_dims': 128, 'fusion_router_dims': 128, 'fusion_outdims': 32}, 'BaselineCLS': {'num_classes': 5, 'pad_mask': 1, 'mode': 'photo', 'output_dir': '/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events', 'stats_file': 'feature_stats_day100.npz', 'horizon_days': 50.0, 'batch_size': 256, 'sampler_balance': True, 'num_workers': 8, 'd_model': 128, 'n_heads': 8, 'n_layers': 4, 'dropout': 0.3, 'max_len': 257, 'lr': 5e-06, 'weight_decay': 0.01, 'focal_gamma': 2.0, 'cut_time_p': False, 'p_dropout': 0.1, 'jitter_scale': 0.1, 'flux_nu': 8, 'epochs': 150, 'patience': 30, 'seed': 42}}, 'criterion': {'name': 'torch.nn.CrossEntropyLoss', 'band_loss_reduction': 'mean'}, 'optimizer': {'name': 'torch.optim.SGD'}, 'torch.optim.SGD': {'lr': 0.01, 'momentum': 0.9}, 'torch.optim.Adam': {'lr': 0.01}, 'train': {'weights_filename': 'example_model.pth', 'epochs': 10, 'resume': False, 'split': 'train', 'experiment_name': 'notebook', 'run_name': False}, 'onnx': {'opset_version': 20}, 'model_inputs': {'data': {'dataset_class': 'HyraxRandomDataset', 'data_location': './data', 'primary_id_field': 'object_id', 'dataset_config': {'size': 1000, 'shape': [4, 64, 64], 'provided_labels': [0, 1, 2, 3, 4], 'metadata_fields': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']}}}, 'data_set': {'name': 'PhotoEventsDataset', 'crop_to': False, 'filters': False, 'filter_catalog': False, 'transform': 'tanh', 'train_size': 0.6, 'validate_size': 0.2, 'test_size': 0.2, 'seed': False, 'use_cache': True, 'preload_cache': True, 'object_id_column_name': False, 'filter_column_name': False, 'filename_column_name': False, 'nan_mode': False, 'nan_quantile': 0.05, 'astropy_table': False, 'semi_width_deg': 0.00472, 'semi_height_deg': 0.00472, 'data_location': '/Users/dbranton/lincc/incubators/photo_events/', 'HyraxRandomDataset': {'size': 100, 'shape': [2, 5, 5], 'seed': 42, 'provided_labels': [0, 1, 2], 'metadata_fields': ['meta_field_1', 'meta_field_2'], 'number_invalid_values': 0, 'invalid_value_type': 'nan'}}, 'data_loader': {'batch_size': 512, 'shuffle': False}, 'infer': {'model_weights_file': False, 'split': False}, 'vector_db': {'name': 'chromadb', 'vector_db_dir': False, 'infer_results_dir': False, 'chromadb': {'shard_size_limit': 65536, 'vector_size_warning': 10000}, 'qdrant': {'vector_size': 64}}, 'results': {'inference_dir': False}, 'umap': {'fit_sample_size': 1024, 'save_fit_umap': True, 'parallel': False, 'name': 'umap.UMAP', 'UMAP': {'n_components': 2, 'n_neighbors': 15}}, 'visualize': {'fields': [], 'display_images': False, 'color_column': False, 'cmap': 'viridis', 'torch_tensor_bands': [3], 'rasterize_plot': False}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e39aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-16 10:07:54,757 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining dataset(s):\u001b[0m\n",
      "Name: data (primary dataset)\n",
      "  Dataset class: HyraxRandomDataset\n",
      "  Data location: ./data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: a, b, c, d, e, f, g, h, i, image, j, k, l, label, m, n, o, object_id, p, q, r, s, t, u, v, w, x, y, z\n",
      "  Dataset config:\n",
      "    size: 1000\n",
      "    shape: [4, 64, 64]\n",
      "    provided_labels: [0, 1, 2, 3, 4]\n",
      "    metadata_fields: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'photometry'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/hyrax/verbs/train.py:63\u001b[39m, in \u001b[36mTrain.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     61\u001b[39m dataset = setup_dataset(config, tensorboardx_logger)\n\u001b[32m     62\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mStyle.BRIGHT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mFore.BLACK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mBack.GREEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mTraining dataset(s):\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mStyle.RESET_ALL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m model = \u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mStyle.BRIGHT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mFore.BLACK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mBack.GREEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mTraining model:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mStyle.RESET_ALL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Create a data loader for the training set (and validation split if configured)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/applecider/lib/python3.12/site-packages/hyrax/pytorch_ignite.py:148\u001b[39m, in \u001b[36msetup_model\u001b[39m\u001b[34m(config, dataset)\u001b[39m\n\u001b[32m    145\u001b[39m model_cls = fetch_model_class(config)\n\u001b[32m    147\u001b[39m \u001b[38;5;66;03m# Pass a single sample of data through the model's to_tensor function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m data_sample = \u001b[43mmodel_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# Provide the data sample for runtime modifications to the model architecture\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_cls(config=config, data_sample=data_sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lincc/incubators/applecider/AppleCider/models/hyrax_models/HyraxBaselineCLS.py:121\u001b[39m, in \u001b[36mHyraxBaselineCLS.to_tensor\u001b[39m\u001b[34m(data_dict)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03mConverts raw data from a dictionary into a PyTorch tensor suitable for the model.\u001b[39;00m\n\u001b[32m    103\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    A tensor of shape (L, 7), where L is the sequence length.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Assuming reading in a data dictionary from an alert npy file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(\u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mphotometry\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mKeyError\u001b[39m: 'photometry'"
     ]
    }
   ],
   "source": [
    "h.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b270b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applecider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
