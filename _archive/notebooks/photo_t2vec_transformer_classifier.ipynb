{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dcfb9d6-2b11-48c4-871b-608297f147ff",
   "metadata": {},
   "source": [
    "# Photometric Event Classification with Time2Vec-Enhanced Transformer\n",
    "\n",
    "This notebook implements an example of the full pipeline our new Transformer-based photometry classifier, with improved time encoding.  It consists of:\n",
    "\n",
    "1. Preprocessing (§1): from raw photometry and alerts to a normalized event‐matrix per object.  \n",
    "2. Model Architecture (§2): a Transformer encoder augmented with a learned Time2Vec embedding.  \n",
    "3. Self-Supervised Pre-Training (§2.3): reconstructing masked tokens over the first 100 days of each light curve.  \n",
    "4. Supervised Fine-Tuning (§2.4): optimizing focal loss for classification at variable observation horizons.  \n",
    "5. Evaluation & Horizon Sweep (§3): plotting Macro-AUPRC, Balanced Accuracy, Top-$k$ and Balanced Top-2 Accuracy as functions of the observation window, to evaluate the early classification capacity.\n",
    "\n",
    "The hyphothesis is that this two‐stage learning procedure, the long‐horizon unsupervised pre‐training followed by short‐horizon supervised tuning lets the model learn rich temporal patterns over the months time scale while specializing to the early light curve behavior that is most predictive of class. \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Preprocessing\n",
    "\n",
    "We convert raw measurements $(t_i, f_i, \\sigma_{f,i})$ into a fixed‐format event sequence $\\mathbf X\\in\\mathbb R^{T\\times F}$ for each object.\n",
    "\n",
    "### 1.1. Merging Simultaneous Observations\n",
    "\n",
    "To reduce noise and redundant data, any consecutive measurements separated by $\\Delta t \\le \\delta$ (e.g.\\ $\\delta=12\\,$h) are collapsed via inverse‐variance weighting:\n",
    "$$\n",
    "w_i = \\frac{1}{\\sigma_{f,i} + \\varepsilon},\\quad\n",
    "\\bar t = \\frac{\\sum_i w_i\\,t_i}{\\sum_i w_i},\\quad\n",
    "\\bar f = \\frac{\\sum_i w_i\\,f_i}{\\sum_i w_i},\\quad\n",
    "\\overline{\\sigma} = \\frac{\\sum_i w_i\\,\\sigma_{f,i}}{\\sum_i w_i}.\n",
    "$$\n",
    "Here $\\varepsilon$ guards against zero error.\n",
    "\n",
    "### 1.2. Feature-Vector Construction\n",
    "\n",
    "After sorting by Modified Julian Date (MJD), for each event $n$ we compute\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Delta t_n &= \\mathrm{MJD}_n - \\mathrm{MJD}_1,\\\\\n",
    "\\delta t_n &= \n",
    "\\begin{cases}\n",
    "\\mathrm{MJD}_n - \\mathrm{MJD}_{n-1}, & n>1,\\\\\n",
    "0, & n=1,\n",
    "\\end{cases}\\\\\n",
    "\\log f_n &= \\log_{10}\\bigl(\\max(f_n,\\,10^{-6})\\bigr),\\\\\n",
    "\\sigma_{\\log f,n} &= \\frac{\\sigma_{f,n}}{f_n\\,\\ln 10},\\\\\n",
    "\\mathbf b_n &\\in\\{0,1\\}^3\\quad\\text{(one-hot for filters $g,r,i$)}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "We also compute colour indices by nearest‐time matching:\n",
    "$$\n",
    "g-r,\\quad r-i\n",
    "$$\n",
    "and record masks $\\mathbf m_n\\in\\{0,1\\}^2$ indicating which colours are valid.  Although colours are computed, the baseline model omits them from the input and uses only\n",
    "$$\n",
    "x_n = \\bigl[\\log(1 + \\Delta t_n),\\; \\log(1 + \\delta t_n),\\;\\log f_n,\\;\\sigma_{\\log f,n},\\;\\mathbf b_n,\\;\\mathbf m_n\\bigr]\\;\\in\\;\\mathbb R^7.\n",
    "$$\n",
    "\n",
    "### 1.3. Dataset Splits & Global Normalization\n",
    "\n",
    "1. Each object’s spectroscopic type is mapped to an integer $y\\in\\{1,\\dots,C\\}$, and object IDs are split into train/val/test (70/15/15 %) while preserving class proportions.  \n",
    "2. We save for each object a compressed file containing its event‐matrix and label, and build manifest_{split}.csv.  \n",
    "3. Over all training events (total $N$ rows, $F$ features) we compute\n",
    "$$\n",
    "\\mu_j = \\frac{1}{N}\\sum_{n=1}^N X_{n,j},\\qquad\n",
    "\\sigma_j = \\sqrt{\\frac{1}{N}\\sum_{n=1}^N\\bigl(X_{n,j}-\\mu_j\\bigr)^2}\\,,\n",
    "$$\n",
    "which are used to normalize the continuous channels. We compute those statistics for light curves under the same truncation as pretraining.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Model Architecture and Training \n",
    "\n",
    "We now describe in detail the architecture of our photometric‐event classifier.  We first normalize the continuous channels:\n",
    "$$\n",
    "\\tilde x_{n,j} = \\frac{x_{n,j}-\\mu_j}{\\sigma_j},\\quad j\\in\\{ \\log(1 + \\Delta t), \\ \\log(1 + \\delta t), \\ \\log f, \\ \\sigma_{\\log f}\\},\n",
    "$$\n",
    "and then concatenate with the one‐hot band vector $\\mathbf b_n$ and mask bits to obtain the final input $\\tilde x_n \\in\\;\\mathbb R^7.$  \n",
    "\n",
    "#### 2.1 Linear Projection & Time2Vec Embedding  \n",
    "\n",
    "We seek a unified representation of its photometric content and the exact time at which it was observed.  A simple learned affine map lifts $\\tilde x_n$ into a $d$-dimensional feature space:  \n",
    "$$\n",
    "e_n \\;=\\; W_{\\mathrm{in}}\\,\\tilde x_n \\;+\\; b_{\\mathrm{in}}\n",
    "\\;\\in\\;\\mathbb R^d.\n",
    "$$  \n",
    "In standard NLP and vision applications, one then adds fixed “sinusoidal” positional encodings to $e_n$ to recover order information.  However, those encodings assume a uniform, discrete index $n$ rather than the irregular, object-dependent timestamps of astronomical surveys.  To address this, we introduce a Time2Vec module, which learns a continuous, data-driven embedding of the elapsed time $\\Delta t_n $. we parametrize  \n",
    "$$\n",
    "\\tau_n\n",
    "\\;=\\;\\bigl[v_n^{(0)},\\,v_n^{(1)},\\,\\dots,\\,v_n^{(d-1)}\\bigr]^\\top\n",
    "\\;\\in\\;\\mathbb R^d\n",
    "$$  \n",
    "with  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_n^{(0)} &= w_0\\,\\Delta t_n + b_0,\\\\\n",
    "v_n^{(i)} &= \\sin\\bigl(w_i\\,\\Delta t_n + b_i\\bigr)\n",
    "\\quad\\text{for } i=1,\\dots,d-1.\n",
    "\\end{aligned}\n",
    "$$  \n",
    "Here the linear component $(w_0,b_0)$ captures broad, monotonic trends in flux or colour over time, while the sinusoidal components $(w_i,b_i)_{i\\ge1}$ learn arbitrary periodicities or quasi-periodic patterns,something fixed encodings cannot adaptively model. Finally, we simply add these two streams of information to form the initial hidden representation  \n",
    "$$\n",
    "h_n^{(0)} \\;=\\; e_n \\;+\\; \\tau_n,\n",
    "$$  \n",
    "this joint embedding $\\{h_n^{(0)}\\}_{n=1}^T$ is then passed directly into the Transformer encoder described next.  \n",
    "\n",
    "\n",
    "#### 2.2 Transformer Encoder  \n",
    "We prepend a learned “CLS” token $h_\\mathrm{CLS}^{(0)}\\in\\mathbb R^d$ to the sequence, yielding\n",
    "$\\bigl[h_\\mathrm{CLS}^{(0)},\\,h_1^{(0)},\\,\\dots,\\,h_T^{(0)}\\bigr]\\in\\mathbb R^{(T+1)\\times d}.$\n",
    "Let $H^{(\\ell)}\\in\\mathbb R^{(T+1)\\times d}$ denote the outputs after $\\ell$ encoder layers.  Each layer comprises:\n",
    "1. Multi‐Head Self‐Attention:  \n",
    "   $$\n",
    "   \\mathrm{MHSA}(Q,K,V)\n",
    "   = \\bigl[\\mathrm{softmax}(QK^\\top/\\sqrt{d_k})\\,V\\bigr]W_O,\n",
    "   $$\n",
    "   with $Q,K,V=W_QH^{(\\ell-1)},\\,W_KH^{(\\ell-1)},\\,W_VH^{(\\ell-1)}$.\n",
    "2. Position‐Wise Feed‐Forward:  \n",
    "   $$\n",
    "   \\mathrm{FFN}(z) = W_2\\,\\mathrm{ReLU}(W_1\\,z + b_1) + b_2.\n",
    "   $$\n",
    "3. Residual & Layer‐Norm before and after each sub‐layer.\n",
    "\n",
    "The encoder produces hidden states\n",
    "$$\n",
    "H^{(\\ell)} = \\mathrm{TransformerEncoder}\\bigl(\\{\\tilde x_n\\}\\bigr)\\in\\mathbb R^{T\\times d}.\n",
    "$$\n",
    "\n",
    "\n",
    "#### 2.3 Self‐Supervised Pre‐Training on 100 d Light Curves\n",
    "\n",
    "Before we ever see a classification label, we “warm up” the Transformer encoder on unlabeled light‐curve fragments spanning the first 100 days of each object.  For each training object we truncate its event sequence to the first $T_{100}$ events with $\\Delta t_n \\le 100$ days, normalize as in §2.1, and construct mini‐batches $\\{x_n\\}_{n=1}^{T_{100}}$.  On each batch we randomly mask a fraction $p$ of the photometric channels (flux, flux‐error, band one-hot), producing masked inputs $\\tilde x_n^{\\mathrm{mask}}$.  In this time window, the encoder produces hidden states\n",
    "$\n",
    "\\mathrm{TransformerEncoder}\\bigl(\\{\\tilde x_n^{\\mathrm{mask}}\\}\\bigr)\\in\\mathbb R^{T_{100}\\times d}.\n",
    "$\n",
    "We discard the CLS token here and focus on per‐token reconstructions: for each position $n$ that was masked, we predict\n",
    "$$\n",
    "\\hat f_n,\\;\\hat b_n,\\;\\widehat{\\delta t}_n\n",
    "$$\n",
    "via three small linear heads on the corresponding hidden vector.  The pre‐training loss on one batch is\n",
    "$$\n",
    "\\mathcal L_{\\mathrm{PT}}\n",
    "= \\lambda_F\\,\\frac{1}{|\\mathcal M|}\\sum_{n\\in\\mathcal M}(f_n-\\hat f_n)^2\n",
    "\\;+\\;\\lambda_B\\,\\frac{1}{|\\mathcal M|}\\sum_{n\\in\\mathcal M}\\mathrm{CE}\\bigl(b_n,\\hat b_n\\bigr)\n",
    "\\;+\\;\\lambda_{\\delta t}\\,\\frac{1}{|\\mathcal M|}\\sum_{n\\in\\mathcal M}(\\delta t_n-\\widehat{\\delta t}_n)^2,\n",
    "$$\n",
    "where $\\mathcal M$ indexes masked positions.  We train for $E_{\\mathrm{PT}}$ epochs with AdamW and cosine‐annealing learning rate, saving the encoder weights $W_{\\mathrm{enc}}^{*}$ at convergence.\n",
    "\n",
    "#### 2.4 Supervised Fine‐Tuning on Variable Horizons\n",
    "\n",
    "After pre-training on the first 100 d of each light curve, we specialize the model to the classification task at shorter “observation horizons” $H_t\\le100\\,$d.  For a given horizon $H_t$ we:\n",
    "\n",
    "1. Truncate each object’s event sequence to those with $\\Delta t_n \\le H_t$, yielding $T_{H_t}$ tokens per object.  \n",
    "2. Normalize & Embed exactly as in §2.1, then pass through the Transformer encoder initialized with the pre-trained weights $W_{\\mathrm{enc}}^*$, to obtain\n",
    "$$\n",
    "H^{(\\ell)} = \\mathrm{TransformerEncoder}\\bigl(\\{\\tilde x_n\\}\\bigr)\\in\\mathbb R^{T_{H_t}\\times d}.\n",
    "$$ \n",
    "3. Classify by extracting the CLS token output,\n",
    "$$\n",
    "z_\\mathrm{CLS} = H^{(\\ell)}_{0}\\in\\mathbb R^d,\n",
    "$$\n",
    "applying LayerNorm and a final linear head to produce class logits\n",
    "   $$\n",
    "   \\hat y_i \\;=\\; W_{\\mathrm{head}}\\;\\mathrm{LayerNorm}(z_{\\mathrm{CLS}})\\;+\\;b_{\\mathrm{head}}\n",
    "   \\;\\in\\;\\mathbb R^C.\n",
    "   $$  \n",
    "\n",
    "where $C$ is the number of classes.\n",
    "\n",
    "We minimize the standard focal loss over the batch of $N_{H_t}$ examples:  \n",
    "$$\n",
    "\\mathcal L_{\\mathrm{focal}}\n",
    "= -\\frac{1}{N_{H_t}} \\sum_{i=1}^{N_{H_t}}\n",
    "\\bigl(1 - p_{i,y_i}\\bigr)^\\gamma \\,\\ln p_{i,y_i},\n",
    "\\quad\n",
    "p_{i,c} = \\mathrm{softmax}(\\hat y_i)_c,\n",
    "$$  \n",
    "where $\\gamma$ is the focusing parameter. To study the best adaptation strategy, we compare two fine-tuning regimes:\n",
    "\n",
    "1. Full Fine-Tuning  \n",
    "   All model parameters (both encoder and head) are updated simultaneously with a single learning rate $\\eta_{\\mathrm{full}}$.  This allows the entire network to adapt to the classification task at horizon $H_t$, but risks “forgetting” some of the rich temporal features learned during pre-training.\n",
    "\n",
    "2. Head-Then-Unfreeze  \n",
    "   - Stage 1 (Head-Only): Freeze the Transformer encoder (keep $W_{\\mathrm{enc}}^*$ fixed) and train only the classification head for a few epochs with a higher learning rate $\\eta_{\\mathrm{head}}$.  This quickly aligns the head to the target classes without disturbing the encoder.  \n",
    "   - Stage 2 (Unfreeze All): Unfreeze the entire model.  Continue training with a differential learning rate schedule: a smaller rate $\\eta_{\\mathrm{enc}}$ for the encoder to preserve pre‐trained features, and a larger rate $\\eta_{\\mathrm{head}}$ for the head to refine decision boundaries.\n",
    "\n",
    "Both strategies use AdamW optimization, early stopping on validation macro-AUPRC, and checkpoint the best weights for downstream evaluation.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Evaluation & Horizon Sweep on Test Set\n",
    "\n",
    "To quantify how performance degrades as we shorten the available light-curve window, we evaluate our fine-tuned models on the held-out test set for each observation horizon $H \\in [1, H_{t}]$. \n",
    "For each horizon $H$, we truncate every object to $\\Delta t_n \\le H$ and compute the following summary metrics:\n",
    "\n",
    "1. Macro-AUPRC  \n",
    "   We compute the area under the precision–recall curve independently for each class and then average:\n",
    "   $$\n",
    "   \\mathrm{AUPRC}_{\\mathrm{macro}}\n",
    "   = \\frac{1}{C}\\sum_{c=1}^C \\mathrm{AP}_c,\n",
    "   $$\n",
    "   where $\\mathrm{AP}_c$ is the average precision for class $c$.  This metric captures the model’s ability to balance precision and recall across all classes, and is especially informative under class imbalance.\n",
    "\n",
    "2. Balanced Accuracy  \n",
    "   We measure recall (true‐positive rate) per class, then average:\n",
    "   $$\n",
    "   \\mathrm{BalAcc}\n",
    "   = \\frac{1}{C}\\sum_{c=1}^C \\frac{\\mathrm{TP}_c}{\\mathrm{TP}_c + \\mathrm{FN}_c}\\,.\n",
    "   $$\n",
    "   Unlike standard accuracy, this treats each class equally and is robust to imbalanced priors.\n",
    "\n",
    "3. Top-$k$ Accuracy  \n",
    "   We check whether the true label $y_i$ lies among the $k$ highest-probability predictions:\n",
    "   $$\n",
    "   \\mathrm{Top}\\!-\\!k\n",
    "   = \\frac{1}{N}\\sum_{i=1}^N \\mathbf{1}\\bigl[y_i \\in \\mathrm{top}_k(\\hat p_i)\\bigr].\n",
    "   $$\n",
    "   By default we report $k=2$, which reflects the model’s ability to include the correct class in its top two guesses.\n",
    "\n",
    "4. Balanced Top-2 Accuracy  \n",
    "   To combine the fairness of balanced accuracy with the flexibility of top-2 predictions, we compute per-class Top-2 recall and then average:\n",
    "   $$\n",
    "   \\mathrm{BalTop2}\n",
    "   = \\frac{1}{C}\\sum_{c=1}^C\n",
    "     \\frac{1}{N_c}\\sum_{i:y_i=c}\n",
    "       \\mathbf{1}\\bigl[y_i \\in \\mathrm{top}_2(\\hat p_i)\\bigr],\n",
    "   $$\n",
    "   where $N_c$ is the number of test examples of class $c$.  This metric answers, “On average, how often is the true class among the model’s two highest-confidence predictions for each class?”\n",
    "\n",
    "By plotting each metric against the observation horizon $H$, we trace how performance evolves as more of the light curve becomes available. The Top-1 and Top-2 accuracy curves show how quickly the model “locks in” the correct class once enough data has been seen. The Balanced Accuracy and Balanced Top-2 curves reveal the model’s fairness across all classes, ensuring that rare transients are not overlooked. Meanwhile, the Macro-AUPRC curve encapsulates the precision-recall trade-off across every class, indicating how well the model distinguishes signal from noise at each horizon. We can use this analysis to diagnose the best operating point for the production version of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a60bf4-17f8-44d1-bc2e-8c61918cb14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548abce6-153f-4655-ae43-7a82c9c65b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(\"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260f15f-3c77-4971-b1fc-2f1cc92b3de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Imports & global knobs -------------------------------------\n",
    "# ===============================================================\n",
    "import os, math, time\n",
    "import numpy as np, pandas as pd, torch\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    top_k_accuracy_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import cm as _cm\n",
    "from collections import Counter\n",
    "\n",
    "# -------- configuration  -----------------------------------------\n",
    "CFG = SimpleNamespace(\n",
    "    # data --------------------------------------------------------\n",
    "    output_dir=\"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events\",\n",
    "    stats_file=\"feature_stats_day100.npz\",\n",
    "    horizon_days=50.0,  # <- fine-tuning on 50 days\n",
    "    batch_size=256,  # 64,\n",
    "    sampler_balance=True,\n",
    "    num_workers=8,\n",
    "    # model -------------------------------------------------------\n",
    "    d_model=128,\n",
    "    n_heads=8,  # 4,\n",
    "    n_layers=4,  # 2,\n",
    "    dropout=0.30,\n",
    "    max_len=257,  # 300,#256,#128,#128,\n",
    "    # optimiser ---------------------------------------------------\n",
    "    lr=5e-6,\n",
    "    weight_decay=1e-2,\n",
    "    # loss & imbalance -------------------------------------------\n",
    "    focal_gamma=2.0,\n",
    "    # augmentation -----------------------------------------------\n",
    "    cut_time_p=None,  # (.25,.25,.25,.25), #None,  # or (.25,.25,.25,.25)\n",
    "    p_dropout=0.1,\n",
    "    jitter_scale=0.10,\n",
    "    flux_nu=8,\n",
    "    # training schedule ------------------------------------------\n",
    "    epochs=150,\n",
    "    patience=30,\n",
    "    # misc --------------------------------------------------------\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "torch.manual_seed(CFG.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ===============================================================\n",
    "#     Taxonomy  -------------------------------------------------\n",
    "# ===============================================================\n",
    "BROAD_CLASSES = [\"SNI\", \"SNII\", \"Cataclysmic\", \"AGN\", \"TDE\"]\n",
    "ORIG2BROAD = {\n",
    "    \"SN Ia\": \"SNI\",\n",
    "    \"SN Ib\": \"SNI\",\n",
    "    \"SN Ic\": \"SNI\",\n",
    "    \"SN II\": \"SNII\",\n",
    "    \"SN IIP\": \"SNII\",\n",
    "    \"SN IIn\": \"SNII\",\n",
    "    \"SN IIb\": \"SNII\",\n",
    "    \"Cataclysmic\": \"Cataclysmic\",\n",
    "    \"AGN\": \"AGN\",\n",
    "    \"Tidal Disruption Event\": \"TDE\",\n",
    "}\n",
    "NUM_CLASSES = len(BROAD_CLASSES)\n",
    "BROAD2ID = {c: i for i, c in enumerate(BROAD_CLASSES)}\n",
    "_SUBCLASS_ID2NAME = [\n",
    "    \"SN Ia\",\n",
    "    \"SN Ib\",\n",
    "    \"SN Ic\",\n",
    "    \"SN II\",\n",
    "    \"SN IIP\",\n",
    "    \"SN IIn\",\n",
    "    \"SN IIb\",\n",
    "    \"Cataclysmic\",\n",
    "    \"AGN\",\n",
    "    \"Tidal Disruption Event\",\n",
    "]\n",
    "ID2BROAD_ID = {i: BROAD2ID[ORIG2BROAD[name]] for i, name in enumerate(_SUBCLASS_ID2NAME)}\n",
    "\n",
    "# ===============================================================\n",
    "#     Dataset / collate  ----------------------------------------\n",
    "# ===============================================================\n",
    "_BAND_OH = np.eye(3, dtype=np.float32)\n",
    "\n",
    "\n",
    "def build_event_tensor(arr):\n",
    "    dt = np.log1p(arr[:, 0])\n",
    "    dt_prev = np.log1p(arr[:, 1])\n",
    "    logf, logfe = arr[:, 3], arr[:, 4]\n",
    "    oh = _BAND_OH[arr[:, 2].astype(np.int64)]\n",
    "    vec4 = np.stack([dt, dt_prev, logf, logfe], 1)\n",
    "    return torch.from_numpy(np.concatenate([vec4, oh], 1))\n",
    "\n",
    "\n",
    "class PhotoEventDataset(Dataset):\n",
    "    def __init__(self, manifest_df, horizon=10.0):\n",
    "        self.df, self.horizon = manifest_df.reset_index(drop=True), horizon\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        raw = np.load(row.filepath)\n",
    "        arr = raw[\"data\"] if isinstance(raw, np.lib.npyio.NpzFile) else raw\n",
    "        if self.horizon:\n",
    "            arr = arr[arr[:, 0] <= self.horizon]\n",
    "        return build_event_tensor(arr.astype(np.float32)), ID2BROAD_ID[int(row.label)]\n",
    "\n",
    "\n",
    "def load_stats(path):\n",
    "    st = np.load(path)\n",
    "    return (torch.from_numpy(st[\"mean\"]), torch.from_numpy(st[\"std\"]))\n",
    "\n",
    "\n",
    "def build_collate(mean, std):\n",
    "    def collate(batch):\n",
    "        seqs, labels = zip(*batch)\n",
    "        lens = [s.size(0) for s in seqs]\n",
    "        pad = pad_sequence(seqs, batch_first=True)\n",
    "        mask = torch.stack([torch.cat([torch.zeros(l), torch.ones(pad.size(1) - l)]) for l in lens]).bool()\n",
    "        cont = (pad[..., :4] - mean) / (std + 1e-8)\n",
    "        return torch.cat([cont, pad[..., 4:]], -1), torch.tensor(labels), mask\n",
    "\n",
    "    return collate\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#    Model  -----------------------------------------------------\n",
    "# ===============================================================\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (NEW) Time2Vec positional encoding\n",
    "# ------------------------------------------------------------------------------\n",
    "class Time2Vec(nn.Module):\n",
    "    \"\"\"\n",
    "    Time2Vec: map scalar time t -> d_model-dimensional vector.\n",
    "    v0 = w0 * t + b0  (linear)\n",
    "    v[i] = sin(w[i] * t + b[i])  for i=1..d_model-1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        # one linear + (d_model-1) periodic features\n",
    "        self.w0 = nn.Parameter(torch.randn(1))\n",
    "        self.b0 = nn.Parameter(torch.zeros(1))\n",
    "        self.w = nn.Parameter(torch.randn(d_model - 1))\n",
    "        self.b = nn.Parameter(torch.zeros(d_model - 1))\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        t: (B, L)  - scalar \"time since first detection\" per event\n",
    "        returns (B, L, d_model)\n",
    "        \"\"\"\n",
    "        # linear term\n",
    "        v0 = self.w0 * t + self.b0  # (B, L)\n",
    "        # periodic terms\n",
    "        vp = torch.sin(t.unsqueeze(-1) * self.w + self.b)  # (B, L, d_model-1)\n",
    "        return torch.cat([v0.unsqueeze(-1), vp], dim=-1)  # (B, L, d_model)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (NEW) Transformer Encoder + class token\n",
    "# ------------------------------------------------------------------------------\n",
    "class BaselineCLS(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, num_classes, dropout, max_len=None):\n",
    "        super().__init__()\n",
    "        self.in_proj = nn.Linear(7, d_model)\n",
    "        self.cls_tok = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "\n",
    "        # replace SinCos PE with Time2Vec on the dt channel\n",
    "\n",
    "        self.time2vec = Time2Vec(d_model)\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model, n_heads, d_model * 4, dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, n_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.head = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x, pad_mask):\n",
    "        \"\"\"\n",
    "        x: (B, L, 7)  - the raw event tensor from build_event_tensor\n",
    "            channels: [ dt, dt_prev, logf, logfe, one-hot-band(3) ]\n",
    "        pad_mask: (B, L) boolean\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape\n",
    "\n",
    "        # project into model dim\n",
    "        h = self.in_proj(x)  # (B, L, d_model)\n",
    "        # extract the *continuous* log1p dt feature\n",
    "        t = x[..., 0]  # (B, L)\n",
    "\n",
    "        # compute the learned time embedding:\n",
    "        te = self.time2vec(t)  # (B, L, d_model)\n",
    "\n",
    "        # add it:\n",
    "        h = h + te  # (B, L, d_model)\n",
    "\n",
    "        # prepend a learned CLS token:\n",
    "        tok = self.cls_tok.expand(B, -1, -1)  # (B,1,d_model)\n",
    "        h = torch.cat([tok, h], dim=1)  # (B, L+1, d_model)\n",
    "\n",
    "        # adjust padding mask to account for CLS at idx=0\n",
    "        pad = torch.cat([torch.zeros(B, 1, device=pad_mask.device, dtype=torch.bool), pad_mask], dim=1)\n",
    "\n",
    "        # encode\n",
    "        z = self.encoder(h, src_key_padding_mask=pad)  # (B, L+1, d_model)\n",
    "\n",
    "        # classification from the CLS token\n",
    "        return self.head(self.norm(z[:, 0]))  # (B, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3a84b-a537-48d9-b796-8d970fbc442c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Self-supervised Masked-Event Pre-Training (ME-MPT) with Time2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625b00f-3ec8-4cb6-8c23-1ede63c82460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#     Self-supervised Masked-Event Pre-Training (ME-MPT) with Time2Vec\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np, pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Hyper-parameters ---------------------------------------------------------\n",
    "MASK_P = 0.30  # fraction of tokens to mask\n",
    "PT_EPOCHS = 50\n",
    "PT_BATCH = 256\n",
    "PT_LR = 5e-4\n",
    "PT_OUTFILE = \"mpt_encoder.pt\"\n",
    "LAMBDA_F = 5.0  # boost flux head\n",
    "LAMBDA_B = 5.0  # boost band head\n",
    "LAMBDA_DT = 1.0  # log1p Δt head\n",
    "\n",
    "# --- Build the 100-day DataLoader ----------------------------------------------\n",
    "out_dir = Path(CFG.output_dir)\n",
    "# train_df_full = pd.read_csv(out_dir/\"manifest_train.csv\")\n",
    "# ds_pt         = PhotoEventDataset(train_df_full, horizon=100)\n",
    "# mean, std     = load_stats(out_dir/CFG.stats_file)\n",
    "# ld_pt         = DataLoader(\n",
    "#    ds_pt, batch_size=PT_BATCH, shuffle=True,\n",
    "#    collate_fn=build_collate(mean, std),\n",
    "#    num_workers=CFG.num_workers, pin_memory=True\n",
    "# )\n",
    "\n",
    "\n",
    "# --- MPT heads ----------------------------------------------------------------\n",
    "class MPTModel(torch.nn.Module):\n",
    "    def __init__(self, base_enc):\n",
    "        super().__init__()\n",
    "        self.encoder = base_enc.encoder\n",
    "        d = base_enc.in_proj.out_features\n",
    "        self.head_flux = torch.nn.Linear(d, 1)\n",
    "        self.head_band = torch.nn.Linear(d, 3)\n",
    "        self.head_dt = torch.nn.Linear(d, 1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return (\n",
    "            self.head_flux(z),  # (B, L, 1)\n",
    "            self.head_band(z),  # (B, L, 3)\n",
    "            self.head_dt(z),  # (B, L, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "# --- Masking helper  ----------------------------------------------------------\n",
    "def mask_batch(x, pad_mask):\n",
    "    masked = torch.zeros_like(pad_mask)\n",
    "    for b in range(x.size(0)):\n",
    "        valid = (~pad_mask[b]).nonzero(as_tuple=True)[0]\n",
    "        k = max(int(len(valid) * MASK_P), 1)  # leave ≥1 token\n",
    "        idx = valid[torch.randperm(len(valid))[:k]]\n",
    "        # only zero-out photometry channels: logflux (2), logflux_err (3), bands (4–6)\n",
    "        x[b, idx, 2:7] = 0.0\n",
    "        masked[b, idx] = True\n",
    "    return masked\n",
    "\n",
    "\n",
    "# --- Instantiate everything -------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "enc = BaselineCLS(\n",
    "    d_model=CFG.d_model,\n",
    "    n_heads=CFG.n_heads,\n",
    "    n_layers=CFG.n_layers,\n",
    "    dropout=CFG.dropout,\n",
    "    max_len=CFG.max_len,\n",
    "    num_classes=NUM_CLASSES,\n",
    ").to(device)\n",
    "mpt = MPTModel(enc).to(device)\n",
    "\n",
    "opt = AdamW(\n",
    "    [\n",
    "        {\"params\": enc.encoder.parameters(), \"lr\": PT_LR * 0.5},\n",
    "        {\n",
    "            \"params\": list(mpt.head_flux.parameters())\n",
    "            + list(mpt.head_band.parameters())\n",
    "            + list(mpt.head_dt.parameters()),\n",
    "            \"lr\": PT_LR,\n",
    "        },\n",
    "    ],\n",
    "    weight_decay=1e-2,\n",
    ")\n",
    "sched = CosineAnnealingLR(opt, T_max=PT_EPOCHS)\n",
    "\n",
    "# flux_losses, band_losses, dt_losses, total_losses = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bc550-8100-4be1-aa41-b76ea3fadea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## --- Pre-training loop --------------------------------------------------------\n",
    "for ep in range(1, PT_EPOCHS + 1):\n",
    "    mpt.train()\n",
    "    ep_f = ep_b = ep_d = ep_t = 0.0\n",
    "\n",
    "    for x_mask, _, pad_mask in ld_pt:\n",
    "        x_mask, pad_mask = x_mask.to(device), pad_mask.to(device)\n",
    "        x_orig = x_mask.detach().clone()\n",
    "\n",
    "        # 1) mask photometry only\n",
    "        masked_tok = mask_batch(x_mask, pad_mask)\n",
    "\n",
    "        # 2) build Transformer inputs\n",
    "        emb = enc.in_proj(x_mask)  # (B,L,d)\n",
    "        te = F.dropout(enc.time2vec(x_mask[..., 0]), p=0.1)  # (B,L,d)\n",
    "        h_in = emb + te  # (B,L,d)\n",
    "        B = h_in.size(0)\n",
    "        tok = enc.cls_tok.expand(B, 1, -1)  # (B,1,d)\n",
    "        h = torch.cat([tok, h_in], dim=1)  # (B,L+1,d)\n",
    "        pad = torch.cat([pad_mask.new_zeros((B, 1)), pad_mask], 1)\n",
    "\n",
    "        # 3) encode & drop CLS\n",
    "        z_full = enc.encoder(h, src_key_padding_mask=pad)  # (B,L+1,d)\n",
    "        h_masked = z_full[:, 1:]  # (B,L,d)\n",
    "\n",
    "        # 4) predict\n",
    "        f_hat, b_hat, dt_hat = mpt(h_masked)\n",
    "        mf = masked_tok.view(-1)\n",
    "\n",
    "        # -- flux MSE --\n",
    "        true_f = x_orig[..., 2].view(-1)\n",
    "        loss_f = F.mse_loss(f_hat.view(-1)[mf], true_f[mf])\n",
    "\n",
    "        # -- band CE --\n",
    "        true_b = x_orig[..., 4:7].argmax(-1).view(-1)\n",
    "        loss_b = F.cross_entropy(b_hat.view(-1, 3)[mf], true_b[mf])\n",
    "\n",
    "        # -- time MSE --\n",
    "        dt_gt = torch.roll(x_orig[..., 1], -1, dims=1)\n",
    "        dt_gt[:, -1] = 0.0\n",
    "        dt_gt = dt_gt.view(-1)\n",
    "        loss_dt = F.mse_loss(dt_hat[..., 0].view(-1)[mf], dt_gt[mf])\n",
    "\n",
    "        # -- weighted sum & step --\n",
    "        loss = LAMBDA_F * loss_f + LAMBDA_B * loss_b + LAMBDA_DT * loss_dt\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # store for stats\n",
    "        ep_f += loss_f.item()\n",
    "        ep_b += loss_b.item()\n",
    "        ep_d += loss_dt.item()\n",
    "        ep_t += loss.item()\n",
    "\n",
    "    # scheduler & record\n",
    "    sched.step()\n",
    "    n_batches = len(ld_pt)\n",
    "    flux_losses.append(ep_f / n_batches)\n",
    "    band_losses.append(ep_b / n_batches)\n",
    "    dt_losses.append(ep_d / n_batches)\n",
    "    total_losses.append(ep_t / n_batches)\n",
    "\n",
    "    print(\n",
    "        f\"Ep{ep:02d} | flux {flux_losses[-1]:.4f} | band {band_losses[-1]:.4f} | dt {dt_losses[-1]:.4f} | total {total_losses[-1]:.4f}\"\n",
    "    )\n",
    "\n",
    "# --- save encoder ------------------------------------------------------------\n",
    "torch.save(enc.state_dict(), PT_OUTFILE)\n",
    "print(\"Saved pretrained encoder to\", PT_OUTFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329502c-dd3a-4329-9eb7-6a3adc6adabf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pretraining diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebaf9e6-8455-4dc7-b4d7-f7b22b9392fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot pretraining diagnostics\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870973f9-4bff-4f81-8716-e75ed978563a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---    Loss Curves -------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(flux_losses, label=\"Flux MSE\", linewidth=2)\n",
    "ax.plot(dt_losses, label=\"Time MSE\", linewidth=2)\n",
    "ax.plot(total_losses, label=\"Total Loss\", linewidth=2)\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Loss\", title=\"ME-MPT Pretraining Losses\")\n",
    "ax.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---    Gather masked-token reconstructions ------------------------------------\n",
    "all_tf, all_pf = [], []\n",
    "all_td, all_pd = [], []\n",
    "all_tb, all_pb = [], []\n",
    "\n",
    "for _ in range(20):  # use first 20 batches\n",
    "    x_m, _, pad = next(iter(ld_pt))\n",
    "    x_m, pad = x_m.to(device), pad.to(device)\n",
    "    orig = x_m.clone()\n",
    "    mask = mask_batch(x_m, pad)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = enc.in_proj(x_m)\n",
    "        te = enc.time2vec(x_m[..., 0])\n",
    "        h = emb + te\n",
    "        B = h.size(0)\n",
    "        tok = enc.cls_tok.expand(B, 1, -1)\n",
    "        h = torch.cat([tok, h], dim=1)\n",
    "        pad_full = torch.cat([pad.new_zeros((B, 1)), pad], 1)\n",
    "        z = enc.encoder(h, src_key_padding_mask=pad_full)[:, 1:]\n",
    "        f_hat = mpt.head_flux(z)[..., 0].cpu().numpy()\n",
    "        dt_hat = mpt.head_dt(z)[..., 0].cpu().numpy()\n",
    "        b_hat = mpt.head_band(z).cpu().numpy()\n",
    "\n",
    "    x_np = orig.cpu().numpy()\n",
    "    mask_np = mask.cpu().numpy()\n",
    "\n",
    "    for i in range(x_np.shape[0]):\n",
    "        idxs = np.where(mask_np[i])[0]\n",
    "        all_tf.extend(x_np[i, idxs, 2])\n",
    "        all_pf.extend(f_hat[i, idxs])\n",
    "        all_td.extend(np.roll(x_np[i, :, 1], -1)[idxs])\n",
    "        all_pd.extend(dt_hat[i, idxs])\n",
    "        all_tb.extend(x_np[i, idxs, 4:7].argmax(1))\n",
    "        all_pb.extend(b_hat[i, idxs].argmax(1))\n",
    "\n",
    "true_f, pred_f = np.array(all_tf), np.array(all_pf)\n",
    "true_dt, pred_dt = np.array(all_td), np.array(all_pd)\n",
    "true_b, pred_b = np.array(all_tb), np.array(all_pb)\n",
    "\n",
    "# ---   Flux & Δt Reconstruction ---------------------------------------------\n",
    "# invert the log1p transform\n",
    "raw_true_dt = np.expm1(true_dt)\n",
    "raw_pred_dt = np.expm1(pred_dt)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), dpi=300)\n",
    "\n",
    "# --- Flux  ---\n",
    "hb1 = ax1.hexbin(true_f, pred_f, gridsize=50, cmap=\"Blues\", mincnt=1, norm=LogNorm())\n",
    "ax1.plot([true_f.min(), true_f.max()], [true_f.min(), true_f.max()], \"r--\")\n",
    "ax1.set(\n",
    "    xlabel=\"True log-flux\",\n",
    "    ylabel=\"Predicted log-flux\",\n",
    "    title=f\"Flux Recon (R²={r2_score(true_f, pred_f):.3f})\",\n",
    ")\n",
    "fig.colorbar(hb1, ax=ax1, label=\"count (log scale)\")\n",
    "\n",
    "# --- Δt  ---\n",
    "hb2 = ax2.hexbin(raw_true_dt, raw_pred_dt, gridsize=50, cmap=\"Greens\", mincnt=1, norm=LogNorm())\n",
    "ax2.plot([raw_true_dt.min(), raw_true_dt.max()], [raw_true_dt.min(), raw_true_dt.max()], \"r--\")\n",
    "ax2.set(\n",
    "    xlabel=\"True Δt (days)\",\n",
    "    ylabel=\"Predicted Δt (days)\",\n",
    "    title=f\"Δt Recon (raw, R²={r2_score(raw_true_dt, raw_pred_dt):.3f})\",\n",
    ")\n",
    "fig.colorbar(hb2, ax=ax2, label=\"count (log scale)\")\n",
    "ax2.set_xlim(0, 50)\n",
    "ax2.set_ylim(0, 50)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---    Band Confusion Matrix & Accuracy --------------------------------------\n",
    "cm = confusion_matrix(true_b, pred_b, labels=[0, 1, 2])\n",
    "acc = accuracy_score(true_b, pred_b)\n",
    "plt.figure(figsize=(4, 4), dpi=300)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\", xticklabels=[\"g\", \"r\", \"i\"], yticklabels=[\"g\", \"r\", \"i\"])\n",
    "plt.title(f\"Band Confusion (acc={acc:.3f})\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---    Error Distribution by Band  --------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "df_err = pd.DataFrame(\n",
    "    {\"band\": true_b, \"flux_err\": np.abs(true_f - pred_f), \"dt_err\": np.abs(true_dt - pred_dt)}\n",
    ")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=\"band\", y=\"flux_err\", data=df_err, palette=\"pastel\")\n",
    "plt.xticks([0, 1, 2], [\"g\", \"r\", \"i\"])\n",
    "plt.title(\"Flux Error by Band\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=\"band\", y=\"dt_err\", data=df_err, palette=\"pastel\")\n",
    "plt.xticks([0, 1, 2], [\"g\", \"r\", \"i\"])\n",
    "plt.title(\"Δt Error by Band\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64cb731-0766-407a-a409-145d3bbe7cca",
   "metadata": {},
   "source": [
    "# Training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c9959-6acf-4d0b-8be9-6cf46a910d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#      Loss / metrics / run_epoch -------------------------------\n",
    "# ===============================================================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.gamma, self.alpha, self.reduction = gamma, alpha, reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        logp = F.log_softmax(logits, 1)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(logits.size(0))\n",
    "        logp_t = logp[idx, target]\n",
    "        p_t = p[idx, target]\n",
    "        if self.alpha is not None:\n",
    "            at = self.alpha[target]\n",
    "            loss = -at * (1 - p_t) ** self.gamma * logp_t\n",
    "        else:\n",
    "            loss = -((1 - p_t) ** self.gamma) * logp_t\n",
    "        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n",
    "\n",
    "\n",
    "def cut_time(mask, dt_first, probs):\n",
    "    B, _ = mask.shape\n",
    "    horizons = np.random.choice([1, 3, 5, 10], size=B, p=probs)\n",
    "    for b, h in enumerate(horizons):\n",
    "        mask[b, dt_first[b] > h] = True\n",
    "\n",
    "\n",
    "def run_epoch(model, loader, optimizer, criterion, is_train):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    tot_loss, tot_correct, tot_N = 0.0, 0, 0\n",
    "    y_true_list, y_prob_list = [], []\n",
    "\n",
    "    for x, y, m in loader:\n",
    "        x, y, m = x.to(device), y.to(device), m.to(device)\n",
    "\n",
    "        # optional horizon-cut augmentation\n",
    "        if is_train and CFG.cut_time_p is not None:\n",
    "            dt_first = x[..., 0].exp() - 1\n",
    "            cut_time(m, dt_first, CFG.cut_time_p)\n",
    "\n",
    "        logits = model(x, m)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # accumulate batch metrics\n",
    "        tot_loss += loss.item() * y.size(0)\n",
    "        tot_correct += (logits.argmax(1) == y).sum().item()\n",
    "        tot_N += y.size(0)\n",
    "\n",
    "        # store for AUPRC\n",
    "        y_true_list.append(y.cpu().numpy())\n",
    "        y_prob_list.append(torch.softmax(logits, 1).cpu().detach().numpy())\n",
    "\n",
    "    # flatten\n",
    "    y_true = np.concatenate(y_true_list)\n",
    "    y_prob = np.concatenate(y_prob_list)\n",
    "\n",
    "    # one-hot encode true labels\n",
    "    y_true_oh = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    # macro-AUPRC\n",
    "    auprc_macro = average_precision_score(y_true_oh, y_prob, average=\"macro\")\n",
    "\n",
    "    # return: loss, accuracy, macro-AUPRC\n",
    "    return tot_loss / tot_N, tot_correct / tot_N, auprc_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc68d3f-8d58-402c-9634-97c8c3eca7d9",
   "metadata": {},
   "source": [
    "# Training: Fine-tuning on chosen horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ef624-af2e-493b-9ced-ce83f0e94073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "#                           FINE-TUNING STRATEGIES\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "# import wandb\n",
    "# import torch\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# common data setup\n",
    "out = Path(CFG.output_dir)\n",
    "# train_df= pd.read_csv(out/\"manifest_train.csv\")\n",
    "# val_df  = pd.read_csv(out/\"manifest_val.csv\")\n",
    "test_df = pd.read_csv(out / \"manifest_test.csv\")\n",
    "\n",
    "# --------------- compute how many samples per class we want ----------------\n",
    "# orig_lbls        = train_df.label.map(ID2BROAD_ID).values\n",
    "# counts           = np.bincount(orig_lbls, minlength=NUM_CLASSES)\n",
    "# choose median (or max) so that TDEs are oversampled\n",
    "# target_per_class = int(np.median(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08a495-9629-42e7-a05d-b4811f94e634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Balanced + Augmented Dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "\n",
    "class BalancedAugDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps PhotoEventDataset, keeps all originals,\n",
    "    then adds extra TDE copies (with augmentation) up to `target_per_class`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, manifest_df, labels, target_per_class, horizon=10.0, p_dropout=0.1, jitter_scale=0.02, flux_nu=4\n",
    "    ):\n",
    "        self.base_ds = PhotoEventDataset(manifest_df, horizon)\n",
    "        self.df = manifest_df.reset_index(drop=True)\n",
    "        self.labels = labels\n",
    "        self.target = target_per_class\n",
    "        self.horizon = horizon\n",
    "        self.p_dropout = p_dropout\n",
    "        self.jitter_scale = jitter_scale\n",
    "        self.flux_nu = flux_nu\n",
    "\n",
    "        # index of raw TDEs\n",
    "        self.tde_idx = BROAD2ID[\"TDE\"]\n",
    "        self.orig_tde_idxs = np.where(labels == self.tde_idx)[0].tolist()\n",
    "        raw_tde_count = len(self.orig_tde_idxs)\n",
    "\n",
    "        # compute extras needed\n",
    "        extras = max(0, target_per_class - raw_tde_count)\n",
    "        self.extra_idxs = list(np.random.choice(self.orig_tde_idxs, extras, replace=True))\n",
    "\n",
    "        # final index list: all examples + extras\n",
    "        self.indices = list(range(len(self.base_ds))) + self.extra_idxs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ds_idx = self.indices[i]\n",
    "        tensor, label = self.base_ds[ds_idx]\n",
    "\n",
    "        # if this is an extra TDE, rebuild & augment\n",
    "        if label == self.tde_idx and i >= len(self.base_ds):\n",
    "            row = self.df.iloc[ds_idx]\n",
    "            raw = np.load(row.filepath)\n",
    "            arr = raw[\"data\"] if isinstance(raw, np.lib.npyio.NpzFile) else raw\n",
    "            arr = arr[arr[:, 0] <= self.horizon]\n",
    "            if len(arr) == 0:\n",
    "                arr = arr[:1]\n",
    "\n",
    "            # 1. dropout\n",
    "            keep = np.random.rand(len(arr)) > self.p_dropout\n",
    "            keep[0] = True\n",
    "            arr = arr[keep]\n",
    "            if len(arr) == 0:\n",
    "                arr = arr[:1]\n",
    "\n",
    "            # 2. dt‐jitter\n",
    "            t0 = arr[:, 0]\n",
    "            ints = np.diff(np.concatenate([[0.0], t0]))\n",
    "            noise = np.random.randn(len(ints)) * (self.jitter_scale * ints)\n",
    "            ints = np.clip(ints + noise, 0, None)\n",
    "            tnew = np.cumsum(ints)\n",
    "            arr[:, 0] = tnew\n",
    "            arr[:, 1] = np.concatenate([[0.0], ints[:-1]])\n",
    "\n",
    "            # 3. flux‐jitter\n",
    "            logf, logfe = arr[:, 3], arr[:, 4]\n",
    "            f, ferr = np.exp(logf), np.exp(logfe)\n",
    "            scale = 0.15 * ferr\n",
    "            fnew = student_t(df=self.flux_nu, loc=f, scale=scale).rvs()\n",
    "            arr[:, 3] = np.log(np.clip(fnew, 1e-8, None))\n",
    "\n",
    "            tensor = build_event_tensor(arr.astype(np.float32))\n",
    "\n",
    "        return tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516be97-a71f-4fb6-b8fc-8fcc4c93c891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  make_loaders() for fine‐tuning\n",
    "# ------------------------------------------------------------------------------\n",
    "def make_loaders():\n",
    "    out = Path(CFG.output_dir)\n",
    "    # train_df   = pd.read_csv(out/\"manifest_train.csv\")\n",
    "    # val_df     = pd.read_csv(out/\"manifest_val.csv\")\n",
    "    test_df = pd.read_csv(out / \"manifest_test.csv\")\n",
    "\n",
    "    orig_labels = train_df.label.map(ID2BROAD_ID).values\n",
    "    counts = np.bincount(orig_labels, minlength=NUM_CLASSES)\n",
    "    # choose reference to match. SNII is a good one\n",
    "    ref_idx = BROAD2ID[\"SNII\"]\n",
    "    target_per_class = int(counts[ref_idx])\n",
    "\n",
    "    mean, std = load_stats(out / CFG.stats_file)\n",
    "    collate = build_collate(mean, std)\n",
    "\n",
    "    # train loader with TDE oversampling + augmentation\n",
    "    # train_ds = BalancedAugDataset(\n",
    "    #    manifest_df      = train_df,\n",
    "    #    labels           = orig_labels,\n",
    "    #    target_per_class = target_per_class,\n",
    "    #    horizon          = CFG.horizon_days,\n",
    "    #    p_dropout        = CFG.p_dropout,\n",
    "    #    jitter_scale     = CFG.jitter_scale,\n",
    "    #    flux_nu          = CFG.flux_nu\n",
    "    # )\n",
    "\n",
    "    # -- balance batches across all classes via WeightedRandomSampler --\n",
    "    # gather per-sample weights = 1 / class_freq\n",
    "    all_labels = []\n",
    "    for idx in train_ds.indices:\n",
    "        all_labels.append(orig_labels[idx])\n",
    "    freqs = Counter(all_labels)\n",
    "    # weight per sample inversely proportional to its class frequency\n",
    "    sample_weights = [1.0 / freqs[lbl] for lbl in all_labels]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # train_ld = DataLoader(\n",
    "    #    train_ds,\n",
    "    #    batch_size        = CFG.batch_size,\n",
    "    #    sampler           = sampler,\n",
    "    #    num_workers       = CFG.num_workers,\n",
    "    #    collate_fn        = collate,\n",
    "    #    pin_memory        = True\n",
    "    # )\n",
    "    #\n",
    "    ## val & test loaders don't take augmentation\n",
    "    # val_ds  = PhotoEventDataset(val_df, CFG.horizon_days)\n",
    "    test_ds = PhotoEventDataset(test_df, CFG.horizon_days)\n",
    "    # val_ld  = DataLoader(val_ds,  batch_size=CFG.batch_size, shuffle=False,\n",
    "    #                     num_workers=CFG.num_workers, collate_fn=collate, pin_memory=True)\n",
    "    test_ld = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        collate_fn=collate,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_ld, val_ld, test_ld\n",
    "\n",
    "\n",
    "mean, std = load_stats(out / CFG.stats_file)\n",
    "collate = build_collate(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37cede-4e25-4c87-96d5-546aa4e5af28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = PhotoEventDataset\n",
    "(test_df, CFG.horizon_days)\n",
    "test_ld = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.num_workers,\n",
    "    collate_fn=collate,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec3d9ce-d11f-4a48-ac51-fa7996a4939f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "#                            STRATEGY A: FULL FINE-TUNING\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "# wandb.init(project=\"photo_test\",\n",
    "#           name=\"full_finetune_all_params\",\n",
    "#           config=CFG.__dict__)\n",
    "ckpt_full = \"/projects/bcrv/abrown3/AppleCiDEr_Skyportal/pt/ft_full.pt\"\n",
    "\n",
    "# build & load\n",
    "model_full = BaselineCLS(CFG.d_model, CFG.n_heads, CFG.n_layers, NUM_CLASSES, CFG.dropout, CFG.max_len).to(\n",
    "    device\n",
    ")\n",
    "pre = torch.load(\"/projects/bcrv/abrown3/AppleCiDEr_Skyportal/pt/mpt_encoder.pt\", map_location=device)\n",
    "sd = model_full.state_dict()\n",
    "# copy only encoder weights (keys that match and not head)\n",
    "for k, v in pre.items():\n",
    "    if k in sd and not k.startswith(\"head.\"):\n",
    "        sd[k] = v\n",
    "model_full.load_state_dict(sd)\n",
    "\n",
    "# optimizer on all params\n",
    "opt_full = torch.optim.AdamW(model_full.parameters(), lr=4e-4, weight_decay=1e-2)\n",
    "\n",
    "# data\n",
    "train_ld, val_ld, test_ld = make_loaders()\n",
    "\n",
    "# train\n",
    "best, patience = 0.0, 0\n",
    "# for ep in range(1, CFG.epochs+1):\n",
    "#    #tr_loss, tr_acc, tr_auprc = run_epoch(model_full, train_ld, opt_full, FocalLoss(CFG.focal_gamma,None), True)\n",
    "#    #va_loss, va_acc, va_auprc = run_epoch(model_full, val_ld,   None, opt_full.criterion if False else FocalLoss(CFG.focal_gamma,None), False)\n",
    "#    #wandb.log({\n",
    "#    #  \"ft_full/train_loss\":tr_loss, \"ft_full/train_acc\":tr_acc, \"ft_full/train_auprc\":tr_auprc,\n",
    "#    #  \"ft_full/val_loss\":va_loss,   \"ft_full/val_acc\":va_acc,   \"ft_full/val_auprc\":va_auprc\n",
    "#    #}, step=ep)\n",
    "#    if va_auprc>best+1e-4:\n",
    "#        best,patience = va_auprc,0\n",
    "#        torch.save(model_full.state_dict(), ckpt_full)\n",
    "#    else:\n",
    "#        patience+=1\n",
    "#        if patience>=CFG.patience:\n",
    "#            print(f\"[FULL] early stop at ep{ep}, best val AUPRC={best:.4f}\")\n",
    "#            break\n",
    "#    print(f\"[FULL] EP{ep:02d} | tr {tr_loss:.3f}/{tr_acc:.3f}/{tr_auprc:.3f} | va {va_loss:.3f}/{va_acc:.3f}/{va_auprc:.3f}\")\n",
    "\n",
    "# final eval\n",
    "# evaluate(model_full, val_ld, \"full_finetune_val\", ckpt_full, tau_per_class=None)\n",
    "evaluate(model_full, test_ld, \"full_finetune_test\", ckpt_full, tau_per_class=None)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc8203-f2ef-44ff-9066-9b111053fa98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "#                   STRATEGY B: HEAD-ONLY → UNFREEZE → FULL\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "wandb.init(project=\"apple_photo\", name=\"head_then_full\", config=CFG.__dict__)\n",
    "ckpt_head = \"/projects/bcrv/abrown3/AppleCiDEr_Skyportal/pt/ft_head_then_full.pt\"\n",
    "\n",
    "# build & load\n",
    "model_h2f = BaselineCLS(CFG.d_model, CFG.n_heads, CFG.n_layers, NUM_CLASSES, CFG.dropout, CFG.max_len).to(\n",
    "    device\n",
    ")\n",
    "sd2 = model_h2f.state_dict()\n",
    "for k, v in pre.items():\n",
    "    if k in sd2 and not k.startswith(\"head.\"):\n",
    "        sd2[k] = v\n",
    "model_h2f.load_state_dict(sd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936646b4-11de-467d-822e-2315f1ac0c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fcc958a-420e-4fec-92b9-af8ae28d4f32",
   "metadata": {},
   "source": [
    "# freeze encoder, train head only\n",
    "for name, p in model_h2f.named_parameters():\n",
    "    if not name.startswith(\"head.\"):\n",
    "        p.requires_grad = False\n",
    "\n",
    "head_opt = torch.optim.AdamW(model_h2f.head.parameters(),\n",
    "                             lr=5.6e-3, weight_decay=1e-2)\n",
    "crit     = FocalLoss(CFG.focal_gamma, None)\n",
    "\n",
    "train_ld, val_ld, test_ld = make_loaders()\n",
    "\n",
    "for ep in range(1, 6):\n",
    "    tr_loss, tr_acc, tr_auprc = run_epoch(model_h2f, train_ld, head_opt, crit, True)\n",
    "    va_loss, va_acc, va_auprc = run_epoch(model_h2f, val_ld,   None, crit, False)\n",
    "    wandb.log({\n",
    "      \"h2f_head/train_loss\":tr_loss, \"h2f_head/train_acc\":tr_acc, \"h2f_head/train_auprc\":tr_auprc,\n",
    "      \"h2f_head/val_loss\":va_loss,   \"h2f_head/val_acc\":va_acc,   \"h2f_head/val_auprc\":va_auprc\n",
    "    }, step=ep)\n",
    "    print(f\"[HEAD] EP{ep:02d} | tr {tr_loss:.3f}/{tr_acc:.3f}/{tr_auprc:.3f} | va {va_loss:.3f}/{va_acc:.3f}/{va_auprc:.3f}\")\n",
    "\n",
    "# unfreeze all, lower lr on encoder\n",
    "for p in model_h2f.parameters(): p.requires_grad = True\n",
    "full_opt = torch.optim.AdamW([\n",
    "    {\"params\": model_h2f.encoder.parameters(), \"lr\":2.4e-4},\n",
    "    {\"params\": model_h2f.head.parameters(),    \"lr\":8e-4},\n",
    "], weight_decay=1e-2)\n",
    "\n",
    "best, patience = 0.0, 0\n",
    "for ep in range(1, CFG.epochs+1):\n",
    "    tr_loss, tr_acc, tr_auprc = run_epoch(model_h2f, train_ld, full_opt, crit, True)\n",
    "    va_loss, va_acc, va_auprc = run_epoch(model_h2f, val_ld,   None, crit, False)\n",
    "    wandb.log({\n",
    "      \"h2f_full/train_loss\":tr_loss, \"h2f_full/train_acc\":tr_acc, \"h2f_full/train_auprc\":tr_auprc,\n",
    "      \"h2f_full/val_loss\":va_loss,   \"h2f_full/val_acc\":va_acc,   \"h2f_full/val_auprc\":va_auprc\n",
    "    }, step=ep)\n",
    "    if va_auprc>best+1e-4:\n",
    "        best,patience = va_auprc,0\n",
    "        torch.save(model_h2f.state_dict(), ckpt_head)\n",
    "    else:\n",
    "        patience+=1\n",
    "        if patience>=CFG.patience:\n",
    "            print(f\"[H2F] early stop at ep{ep}, best val AUPRC={best:.4f}\")\n",
    "            break\n",
    "    print(f\"[H2F] EP{ep:02d} | tr {tr_loss:.3f}/{tr_acc:.3f}/{tr_auprc:.3f} | va {va_loss:.3f}/{va_acc:.3f}/{va_auprc:.3f}\")\n",
    "\n",
    "# final eval\n",
    "#evaluate(model_h2f, val_ld, \"head_then_full_val\", ckpt_head, tau_per_class=None)\n",
    "#evaluate(model_h2f, test_ld, \"head_then_full_test\", ckpt_head, tau_per_class=None)\n",
    "\n",
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4d2aa-f7ef-422e-aac8-d566418ddd6c",
   "metadata": {},
   "source": [
    "# Early-classification capacity evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c567268-9bda-4aee-ba70-f1d54d6a5f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "#   HORIZON SWEEP CURVES: Macro-AUPRC, Accuracies, Top-2\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import average_precision_score, balanced_accuracy_score, top_k_accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# start a fresh W&B run\n",
    "# wandb.init(\n",
    "#    project=\"photometry_full_finetune_aug\",\n",
    "#    name=\"horizon_sweep_with_all_metrics\",\n",
    "#    reinit=True\n",
    "# )\n",
    "#\n",
    "# define the observation horizons\n",
    "horizons = np.linspace(1, CFG.horizon_days, num=50)  # num=50)\n",
    "nH = len(horizons)\n",
    "nC = NUM_CLASSES\n",
    "\n",
    "\n",
    "def inference_preds(model, loader):\n",
    "    \"\"\"Run model(x, mask) over loader and return (y_true, y_prob).\"\"\"\n",
    "    ys, ps = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y, m in loader:\n",
    "            x, m = x.to(device), m.to(device)\n",
    "            logits = model(x, m)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            ps.append(torch.softmax(logits, 1).cpu().numpy())\n",
    "    return np.concatenate(ys), np.concatenate(ps)\n",
    "\n",
    "\n",
    "# preallocate arrays\n",
    "auprc_full = np.zeros(nH)\n",
    "auprc_h2f = np.zeros(nH)\n",
    "accs_full = np.zeros((nH, nC))\n",
    "accs_h2f = np.zeros((nH, nC))\n",
    "balacc_full = np.zeros(nH)\n",
    "balacc_h2f = np.zeros(nH)\n",
    "top2_full = np.zeros(nH)\n",
    "top2_h2f = np.zeros(nH)\n",
    "btop2_full = np.zeros(nH)\n",
    "btop2_h2f = np.zeros(nH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c5150-f960-4787-b22f-5623e8f62e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda4ea0-dcb8-4904-8b7e-9cde4f3f804e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, h in enumerate(tqdm(horizons, total=len(horizons))):\n",
    "    print(\"i, h: \", i, h)\n",
    "    # build a loader with truncated horizon = h\n",
    "    ds_h = PhotoEventDataset(test_df, horizon=h)\n",
    "    ld_h = DataLoader(\n",
    "        ds_h,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,  # num_workers=CFG.num_workers,\n",
    "        num_workers=3,\n",
    "        collate_fn=collate,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # --- Full fine-tuned model ---\n",
    "    y_f, p_f = inference_preds(model_full, ld_h)\n",
    "    yhat_f = p_f.argmax(1)\n",
    "    y_oh_f = label_binarize(y_f, classes=np.arange(nC))\n",
    "\n",
    "    auprc_full[i] = average_precision_score(y_oh_f, p_f, average=\"macro\")\n",
    "    balacc_full[i] = balanced_accuracy_score(y_f, yhat_f)\n",
    "    top2_full[i] = top_k_accuracy_score(y_f, p_f, k=2)\n",
    "\n",
    "    print(\"per class accuracy\")\n",
    "\n",
    "    # per-class accuracy\n",
    "    for c in range(nC):\n",
    "        mask = y_f == c\n",
    "        accs_full[i, c] = (yhat_f[mask] == c).mean() if mask.sum() > 0 else np.nan\n",
    "\n",
    "    # balanced top-2: average over classes of (true class in top-2?)\n",
    "    per_c = []\n",
    "    for c in range(nC):\n",
    "        mask = y_f == c\n",
    "        if mask.sum() > 0:\n",
    "            # take the two largest logits per sample\n",
    "            top2_preds = np.argsort(p_f[mask], axis=1)[:, -2:]\n",
    "            per_c.append((top2_preds == c).any(axis=1).mean())\n",
    "    btop2_full[i] = np.nanmean(per_c)\n",
    "\n",
    "    print(\"inference_preds(model_h2f, ld_h):\")\n",
    "\n",
    "    # --- Head→Full fine-tuned model ---\n",
    "    y_h2, p_h2 = inference_preds(model_h2f, ld_h)\n",
    "    yhat_h2 = p_h2.argmax(1)\n",
    "    y_oh_h2 = label_binarize(y_h2, classes=np.arange(nC))\n",
    "\n",
    "    auprc_h2f[i] = average_precision_score(y_oh_h2, p_h2, average=\"macro\")\n",
    "    balacc_h2f[i] = balanced_accuracy_score(y_h2, yhat_h2)\n",
    "    top2_h2f[i] = top_k_accuracy_score(y_h2, p_h2, k=2)\n",
    "\n",
    "    # per-class accuracy\n",
    "    for c in range(nC):\n",
    "        mask = y_h2 == c\n",
    "        accs_h2f[i, c] = (yhat_h2[mask] == c).mean() if mask.sum() > 0 else np.nan\n",
    "\n",
    "    # balanced top-2 for head→full\n",
    "    per_c = []\n",
    "    for c in range(nC):\n",
    "        mask = y_h2 == c\n",
    "        if mask.sum() > 0:\n",
    "            top2_preds = np.argsort(p_h2[mask], axis=1)[:, -2:]\n",
    "            per_c.append((top2_preds == c).any(axis=1).mean())\n",
    "    btop2_h2f[i] = np.nanmean(per_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328923b-5cda-4f06-9678-b0bb88b42fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------- Macro‐AUPRC vs Horizon ----------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "ax.plot(horizons, auprc_full, \"-o\", color=\"tomato\", label=\"Full fine-tune\")\n",
    "ax.plot(horizons, auprc_h2f, \"-o\", color=\"steelblue\", label=\"Head→Full\")\n",
    "ax.set(xlabel=\"Horizon (days)\", ylabel=\"Macro-AUPRC\", title=\"Macro-AUPRC vs. Observation Horizon\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "wandb.log({\"horizon_macro_auprc\": wandb.Image(fig)})\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# --------- Per‐Class Accuracy vs Horizon ---------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "for c, cls in enumerate(BROAD_CLASSES):\n",
    "    ax.plot(horizons, accs_full[:, c], \"-\", color=f\"C{c}\", label=f\"{cls} (full)\")\n",
    "    ax.plot(horizons, accs_h2f[:, c], \"--\", color=f\"C{c}\", label=f\"{cls} (h2f)\")\n",
    "ax.set(xlabel=\"Horizon (days)\", ylabel=\"Accuracy\", title=\"Per-Class Accuracy vs. Observation Horizon\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(fontsize=8, ncol=2, loc=\"lower right\")\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "wandb.log({\"horizon_per_class_acc\": wandb.Image(fig)})\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# --------- Balanced Accuracy vs Horizon ----------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "ax.plot(horizons, balacc_full, \"-o\", color=\"darkred\", label=\"Full fine-tune\")\n",
    "ax.plot(horizons, balacc_h2f, \"-o\", color=\"darkcyan\", label=\"Head→Full\")\n",
    "ax.set(xlabel=\"Horizon (days)\", ylabel=\"Balanced Accuracy\", title=\"Balanced Accuracy vs. Observation Horizon\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "wandb.log({\"horizon_balanced_acc\": wandb.Image(fig)})\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# --------- Top-2 Accuracy vs Horizon -------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "ax.plot(horizons, top2_full, \"-o\", color=\"maroon\", label=\"Full fine-tune\")\n",
    "ax.plot(horizons, top2_h2f, \"-o\", color=\"teal\", label=\"Head→Full\")\n",
    "ax.set(xlabel=\"Horizon (days)\", ylabel=\"Top-2 Accuracy\", title=\"Top-2 Accuracy vs. Observation Horizon\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "wandb.log({\"horizon_top2_accuracy\": wandb.Image(fig)})\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# --------- Balanced Top-2 Accuracy vs Horizon ---------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "ax.plot(horizons, btop2_full, \"-o\", color=\"purple\", label=\"Full fine-tune\")\n",
    "ax.plot(horizons, btop2_h2f, \"-o\", color=\"orange\", label=\"Head→Full\")\n",
    "ax.set(\n",
    "    xlabel=\"Horizon (days)\",\n",
    "    ylabel=\"Balanced Top-2 Accuracy\",\n",
    "    title=\"Balanced Top-2 Accuracy vs. Observation Horizon\",\n",
    ")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "wandb.log({\"horizon_bal_top2_accuracy\": wandb.Image(fig)})\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865f782-547a-4198-8f9f-50003f7822bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#    Evaluation helpers  ----------------------------------------\n",
    "# ===============================================================\n",
    "def _threshold_sweep(y_true_oh, probs_dict, beta=2, n_points=101):\n",
    "    rows = []\n",
    "    th_vec = np.linspace(0, 1, n_points)\n",
    "    b2 = beta**2\n",
    "    for src, P in probs_dict.items():\n",
    "        for c in range(P.shape[1]):\n",
    "            y_c = y_true_oh[:, c]\n",
    "            for thr in th_vec:\n",
    "                y_hat = (P[:, c] >= thr).astype(int)\n",
    "                tp = (y_hat & y_c).sum()\n",
    "                fp = (y_hat & ~y_c).sum()\n",
    "                fn = (~y_hat & y_c).sum()\n",
    "                prec = tp / (tp + fp + 1e-9)\n",
    "                rec = tp / (tp + fn + 1e-9)\n",
    "                f1 = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "                fβ = (1 + b2) * prec * rec / (b2 * prec + rec + 1e-9)\n",
    "                rows.append([BROAD_CLASSES[c], src, thr, prec, rec, f1, fβ])\n",
    "    return pd.DataFrame(rows, columns=[\"Class\", \"Source\", \"Thr\", \"Prec\", \"Rec\", \"F1\", \"Fbeta\"])\n",
    "\n",
    "\n",
    "def pick_class_thresholds(df_sweep, beta=2, source=\"Phot\"):\n",
    "    b2 = beta**2\n",
    "    tau = {}\n",
    "    for cls in BROAD_CLASSES:\n",
    "        sub = df_sweep[(df_sweep.Class == cls) & (df_sweep.Source == source)]\n",
    "        prec, rec = sub.Prec.values, sub.Rec.values\n",
    "        fβ = (1 + b2) * prec * rec / (b2 * prec + rec + 1e-9)\n",
    "        tau[cls] = float(sub.iloc[fβ.argmax()].Thr)\n",
    "    return tau\n",
    "\n",
    "\n",
    "def predict_with_thresholds(probs, tau_dict):\n",
    "    y_hat = probs.argmax(1)\n",
    "    keep = probs[np.arange(len(probs)), y_hat] >= np.vectorize(tau_dict.__getitem__)(\n",
    "        [BROAD_CLASSES[c] for c in y_hat]\n",
    "    )\n",
    "    return np.where(keep, y_hat, -1)\n",
    "\n",
    "\n",
    "def inference(model, loader):\n",
    "    ys, ps = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y, m in tqdm(loader, desc=\"INF\", leave=False):\n",
    "            x, m = x.to(device), m.to(device)\n",
    "            logits = model(x, m)\n",
    "            probs = torch.softmax(logits, 1).cpu().numpy()\n",
    "            ys.append(y.numpy())\n",
    "            ps.append(probs)\n",
    "    return np.concatenate(ys), np.concatenate(ps)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, split, ckpt_path, tau_per_class=None, beta=2, return_tau=False):\n",
    "    # load best weights\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    y, p = inference(model, loader)\n",
    "    print(\"y:\", y)\n",
    "    print(\"p:\", p)\n",
    "    y_onehot = label_binarize(y, classes=np.arange(NUM_CLASSES))\n",
    "\n",
    "    # threshold sweep\n",
    "    df_sweep = _threshold_sweep(y_onehot, {\"Phot\": p}, beta=beta)\n",
    "\n",
    "    # learn τ⋆ on val\n",
    "    if tau_per_class is None and split == \"val\":\n",
    "        tau_per_class = pick_class_thresholds(df_sweep, beta=beta, source=\"Phot\")\n",
    "\n",
    "    # naive + thresholded preds\n",
    "    y_naive = p.argmax(1)\n",
    "    y_thr = predict_with_thresholds(p, tau_per_class) if tau_per_class else None\n",
    "\n",
    "    # --- sweep plots ---\n",
    "    fig_thr, axes = plt.subplots(NUM_CLASSES, 1, figsize=(9, 2.4 * NUM_CLASSES), dpi=300, sharex=True)\n",
    "    for ax, cls in zip(axes, BROAD_CLASSES):\n",
    "        sub = df_sweep[df_sweep.Class == cls]\n",
    "        for src, grp in sub.groupby(\"Source\"):\n",
    "            ax.plot(grp.Thr, grp.Fbeta, label=f\"F{beta}-{src}\", color=\"#1f77b4\", lw=2)\n",
    "            ax.plot(grp.Thr, grp.Prec, ls=\"--\", lw=1, color=\"#1f77b4\", alpha=0.7)\n",
    "            ax.plot(grp.Thr, grp.Rec, ls=\":\", lw=1, color=\"#1f77b4\", alpha=0.7)\n",
    "            bi = grp.Fbeta.idxmax()\n",
    "            ax.scatter(grp.loc[bi, \"Thr\"], grp.loc[bi, \"Fbeta\"], color=\"#1f77b4\", s=30)\n",
    "        ax.set_title(cls, loc=\"left\")\n",
    "        ax.set_ylabel(f\"Score (F{beta})\")\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1.02)\n",
    "        ax.legend(frameon=False, fontsize=7)\n",
    "    axes[-1].set_xlabel(\"Decision threshold\")\n",
    "    plt.tight_layout()\n",
    "    wandb.log({f\"{split}/thr_sweep\": wandb.Image(fig_thr)})\n",
    "    # plt.close(fig_thr)\n",
    "    plt.show()\n",
    "\n",
    "    # --- confusion matrix ---\n",
    "\n",
    "    cm = confusion_matrix(y, y_naive)\n",
    "    print(\"confusion matrix\", cm)\n",
    "    cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm[np.isnan(cm_norm)] = 0\n",
    "\n",
    "    def _plot_cm(mat, ax, title, cmap, fmt):\n",
    "        im = ax.imshow(mat, cmap=cmap, vmin=0, vmax=(mat.max() if fmt == \"d\" else 1))\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks(range(NUM_CLASSES))\n",
    "        ax.set_yticks(range(NUM_CLASSES))\n",
    "        ax.set_xticklabels(BROAD_CLASSES, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(BROAD_CLASSES)\n",
    "        for i in range(NUM_CLASSES):\n",
    "            for j in range(NUM_CLASSES):\n",
    "                txt = format(mat[i, j], fmt)\n",
    "                ax.text(\n",
    "                    j,\n",
    "                    i,\n",
    "                    txt,\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"white\" if (mat.max() if fmt == \"d\" else 0.5) < im.norm(mat[i, j]) else \"black\",\n",
    "                )\n",
    "\n",
    "    fig_cm, axs_cm = plt.subplots(1, 2, figsize=(14, 5), dpi=300)\n",
    "    _plot_cm(cm, axs_cm[0], f\"{split} Conf (raw)\", \"Reds\", \"d\")\n",
    "    _plot_cm(cm_norm, axs_cm[1], f\"{split} Conf (norm)\", \"Blues\", \".2f\")\n",
    "    plt.tight_layout()\n",
    "    wandb.log(wandb.Image(fig_cm))\n",
    "    plt.show()\n",
    "    # wandb.log({f'{split}/conf_mats': wandb.Image(fig_cm)})\n",
    "    # plt.close(fig_cm)\n",
    "\n",
    "    # --- ROC + PR curves ---\n",
    "    fig_curv, (ax_roc, ax_pr) = plt.subplots(1, 2, figsize=(14, 6), dpi=300)\n",
    "    colors = plt.get_cmap(\"Dark2\").colors\n",
    "    for i, cls in enumerate(BROAD_CLASSES):\n",
    "        fpr, tpr, _ = roc_curve(y_onehot[:, i], p[:, i])\n",
    "        prec, rec, _ = precision_recall_curve(y_onehot[:, i], p[:, i])\n",
    "        ax_roc.plot(fpr, tpr, color=colors[i], alpha=0.9)\n",
    "        ax_pr.step(rec, prec, where=\"post\", color=colors[i], alpha=0.9)\n",
    "    # micro + macro\n",
    "    fpr_m, tpr_m, _ = roc_curve(y_onehot.ravel(), p.ravel())\n",
    "    prec_m, rec_m, _ = precision_recall_curve(y_onehot.ravel(), p.ravel())\n",
    "    ax_roc.plot(fpr_m, tpr_m, \"k:\", lw=2.5)\n",
    "    ax_pr.step(rec_m, prec_m, \"k:\", where=\"post\", lw=2.5)\n",
    "    # macro\n",
    "    fpr_lin = np.linspace(0, 1, 500)\n",
    "    tpr_lin = np.mean(\n",
    "        [np.interp(fpr_lin, *roc_curve(y_onehot[:, i], p[:, i])[:2]) for i in range(NUM_CLASSES)], axis=0\n",
    "    )\n",
    "    prec_lin = np.linspace(0, 1, 1000)\n",
    "    pr_lin = np.mean(\n",
    "        [\n",
    "            np.interp(\n",
    "                prec_lin,\n",
    "                precision_recall_curve(y_onehot[:, i], p[:, i])[1][::-1],\n",
    "                precision_recall_curve(y_onehot[:, i], p[:, i])[0][::-1],\n",
    "            )\n",
    "            for i in range(NUM_CLASSES)\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    ax_roc.plot(fpr_lin, tpr_lin, \"k\", lw=2.7)\n",
    "    ax_pr.step(prec_lin, pr_lin, \"k\", where=\"post\", lw=2.7)\n",
    "    for ax in (ax_roc, ax_pr):\n",
    "        ax.set_xlim(-0.02, 1.02)\n",
    "        ax.set_ylim(-0.02, 1.02)\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.tick_params(direction=\"in\", length=6, which=\"major\")\n",
    "        ax.tick_params(direction=\"in\", length=4, which=\"minor\")\n",
    "    ax_roc.set_xlabel(\"FPR\")\n",
    "    ax_roc.set_ylabel(\"TPR\")\n",
    "    ax_roc.plot([0, 1], [0, 1], \"k--\", alpha=0.6, lw=0.8)\n",
    "    ax_pr.set_xlabel(\"Recall\")\n",
    "    ax_pr.set_ylabel(\"Precision\")\n",
    "    ax_roc.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    wandb.log({f\"{split}/roc_pr_curves\": wandb.Image(fig_curv)})\n",
    "    plt.close(fig_curv)\n",
    "\n",
    "    # --- TDE-only AUPRC ---------------------------------------\n",
    "    # one-vs-all average precision for the TDE class\n",
    "    tde_idx = BROAD_CLASSES.index(\"TDE\")\n",
    "    y_tde = (y == tde_idx).astype(int)\n",
    "    tde_auprc = average_precision_score(y_tde, p[:, tde_idx])\n",
    "    wandb.log({f\"{split}/auprc_TDE\": tde_auprc})\n",
    "\n",
    "    # --- bar chart vs. stratified baseline -------------------\n",
    "    # build stratified baseline by sampling according to class priors\n",
    "    support = np.bincount(y, minlength=NUM_CLASSES)\n",
    "    priors = support / support.sum()\n",
    "    rng = np.random.default_rng(0)\n",
    "    y_strat = rng.choice(NUM_CLASSES, size=len(y), p=priors)\n",
    "    y_prob_strat = np.tile(priors, (len(y), 1))\n",
    "\n",
    "    # collect metrics\n",
    "    metrics_model = {\n",
    "        \"Accuracy\": (y_naive == y).mean(),\n",
    "        \"Top-2 Acc\": top_k_accuracy_score(y, p, k=2),\n",
    "        \"Macro Prec\": precision_score(y, y_naive, average=\"macro\"),\n",
    "        \"Macro Rec\": recall_score(y, y_naive, average=\"macro\"),\n",
    "        \"Macro F1\": f1_score(y, y_naive, average=\"macro\"),\n",
    "        \"Macro AUPRC\": average_precision_score(y_onehot, p, average=\"macro\"),\n",
    "        \"TDE AUPRC\": tde_auprc,\n",
    "    }\n",
    "    # --- stratified‐baseline metrics  ---\n",
    "    classes = np.arange(NUM_CLASSES)\n",
    "    # one‐hot ground truth for TDE‐AUPRC\n",
    "    y_tde = (y == tde_idx).astype(int)\n",
    "\n",
    "    metrics_base = {\n",
    "        k: (\n",
    "            {\n",
    "                \"Accuracy\": lambda: (y_strat == y).mean(),\n",
    "                \"Top-2 Acc\": lambda: top_k_accuracy_score(y, y_prob_strat, k=2),\n",
    "                \"Macro Prec\": lambda: precision_score(y, y_strat, average=\"macro\"),\n",
    "                \"Macro Rec\": lambda: recall_score(y, y_strat, average=\"macro\"),\n",
    "                \"Macro F1\": lambda: f1_score(y, y_strat, average=\"macro\"),\n",
    "                \"Macro AUPRC\": lambda: average_precision_score(\n",
    "                    label_binarize(y, classes=classes), y_prob_strat, average=\"macro\"\n",
    "                ),\n",
    "                \"TDE AUPRC\": lambda: average_precision_score(y_tde, y_prob_strat[:, tde_idx]),\n",
    "            }[k]()\n",
    "        )\n",
    "        for k in metrics_model\n",
    "    }\n",
    "\n",
    "    names = list(metrics_model.keys())\n",
    "    vals_m = [metrics_model[n] for n in names]\n",
    "    vals_b = [metrics_base[n] for n in names]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4), dpi=100)\n",
    "    x = np.arange(len(names))\n",
    "    w = 0.35\n",
    "    ax.bar(x - w / 2, vals_b, w, label=\"Stratified\", color=\"gray\", alpha=0.7)\n",
    "    ax.bar(x + w / 2, vals_m, w, label=\"Model\", color=plt.get_cmap(\"tab10\")(0))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(names, rotation=25, ha=\"right\")\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(f\"{split}: Model vs Baseline\")\n",
    "    ax.legend(frameon=False, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    wandb.log({f\"{split}/baseline_comparison\": wandb.Image(fig)})\n",
    "    # plt.close(fig)\n",
    "    plt.show()\n",
    "\n",
    "    # --- per-class confidence distributions ---------------\n",
    "    # how confident is the model on its *true* class?\n",
    "    bins = np.linspace(0, 1, 30)\n",
    "    fig, axes = plt.subplots(NUM_CLASSES, 1, figsize=(6, 2.2 * NUM_CLASSES), dpi=100, sharex=True)\n",
    "    for i, cls in enumerate(BROAD_CLASSES):\n",
    "        sub_probs = p[y == i, i]\n",
    "        sns.histplot(\n",
    "            sub_probs,\n",
    "            bins=bins,\n",
    "            stat=\"density\",\n",
    "            kde=True,\n",
    "            ax=axes[i],\n",
    "            color=plt.get_cmap(\"tab10\")(i),\n",
    "            alpha=0.6,\n",
    "        )\n",
    "        axes[i].set_xlim(0, 1)\n",
    "        axes[i].set_ylabel(\"Density\")\n",
    "        axes[i].set_title(f\"{cls}: P(model predicts true class)\")\n",
    "    axes[-1].set_xlabel(\"Predicted probability\")\n",
    "    plt.tight_layout()\n",
    "    # plt.close(fig)\n",
    "    plt.show()\n",
    "\n",
    "    # --- bar chart vs stratified baseline ---\n",
    "    support = np.bincount(y, minlength=NUM_CLASSES)\n",
    "    priors = support / support.sum()\n",
    "    rng = np.random.default_rng(0)\n",
    "    y_strat = rng.choice(NUM_CLASSES, size=len(y), p=priors)\n",
    "    y_prob_strat = np.tile(priors, (len(y), 1))\n",
    "\n",
    "    # collect scalar metrics\n",
    "    f1_m = f1_score(y, y_naive, average=\"macro\")\n",
    "    prec_m = precision_score(y, y_naive, average=\"macro\")\n",
    "    rec_m = recall_score(y, y_naive, average=\"macro\")\n",
    "    auprc = average_precision_score(y_onehot, p, average=\"macro\")\n",
    "    top2 = top_k_accuracy_score(y, p, k=2)\n",
    "    top3 = top_k_accuracy_score(y, p, k=3)\n",
    "    f2_naive = fbeta_score(y, y_naive, average=\"macro\", beta=2)\n",
    "    f2_thr = (\n",
    "        fbeta_score(y[y_thr != -1], y_thr[y_thr != -1], average=\"macro\", beta=2)\n",
    "        if y_thr is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "            f\"{split}/acc\": (y_naive == y).mean(),\n",
    "            f\"{split}/top2_acc\": top2,\n",
    "            f\"{split}/top3_acc\": top3,\n",
    "            f\"{split}/precision_macro\": prec_m,\n",
    "            f\"{split}/recall_macro\": rec_m,\n",
    "            f\"{split}/f1_macro\": f1_m,\n",
    "            f\"{split}/auprc_macro\": auprc,\n",
    "            f\"{split}/f2_naive\": f2_naive,\n",
    "            f\"{split}/f2_thresholded\": f2_thr,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if return_tau and split == \"val\":\n",
    "        return tau_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d217cec-23bd-400d-969d-ddca64293f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#      Main & training + evaluation  ----------------------------\n",
    "# ===============================================================\n",
    "def main(cfg):\n",
    "    # W&B init\n",
    "    wandb.init(project=\"apple_photo\", config=cfg.__dict__)\n",
    "    ckpt_path = \"best_newtrans_baseline.pt\"\n",
    "\n",
    "    # data\n",
    "    out = Path(cfg.output_dir)\n",
    "    train_df = pd.read_csv(out / \"manifest_train.csv\")\n",
    "    # val_df   = pd.read_csv(out/'manifest_val.csv')\n",
    "    test_df = pd.read_csv(out / \"manifest_test.csv\")\n",
    "\n",
    "    # train_ds = PhotoEventDataset(train_df, cfg.horizon_days)\n",
    "    # val_ds   = PhotoEventDataset(val_df,   cfg.horizon_days)\n",
    "    test_ds = PhotoEventDataset(test_df, cfg.horizon_days)\n",
    "\n",
    "    mean, std = load_stats(out / cfg.stats_file)\n",
    "    collate = build_collate(mean, std)\n",
    "\n",
    "    # if cfg.sampler_balance:\n",
    "    #    lbl     = train_df.label.map(ID2BROAD_ID).values\n",
    "    #    weights = 1/np.sqrt(np.bincount(lbl,minlength=NUM_CLASSES))[lbl]\n",
    "    #    sampler = WeightedRandomSampler(torch.from_numpy(weights).float(),\n",
    "    #                                    len(weights), replacement=True)\n",
    "    #    train_ld= DataLoader(train_ds, batch_size=cfg.batch_size,\n",
    "    #                         sampler=sampler, num_workers=cfg.num_workers,\n",
    "    #                         collate_fn=collate, pin_memory=True)\n",
    "    # else:\n",
    "    #    train_ld= DataLoader(train_ds, batch_size=cfg.batch_size,\n",
    "    #                         shuffle=True, num_workers=cfg.num_workers,\n",
    "    #                         collate_fn=collate, pin_memory=True)\n",
    "    # val_ld   = DataLoader(val_ds,   batch_size=cfg.batch_size,\n",
    "    #                      shuffle=False, num_workers=cfg.num_workers,\n",
    "    #                      collate_fn=collate, pin_memory=True)\n",
    "\n",
    "    print(\"DataLoader\")\n",
    "    test_ld = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        collate_fn=collate,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    print(\"model\")\n",
    "    # model, loss, optim, sched\n",
    "    model = BaselineCLS(cfg.d_model, cfg.n_heads, cfg.n_layers, NUM_CLASSES, cfg.dropout, cfg.max_len).to(\n",
    "        device\n",
    "    )\n",
    "    cnts = torch.bincount(torch.tensor(train_df.label.map(ID2BROAD_ID).values), minlength=NUM_CLASSES)\n",
    "    alpha = (1 / torch.sqrt(cnts + 1e-6)).to(device)\n",
    "    # crit  = FocalLoss(cfg.focal_gamma, alpha)\n",
    "    crit = FocalLoss(cfg.focal_gamma, None)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    # training loop\n",
    "    best_auprc = 0.0\n",
    "    patience = 0\n",
    "\n",
    "    # for ep in range(1, CFG.epochs+1):\n",
    "    #    train_loss, train_acc, train_auprc = run_epoch(model, train_ld, opt, crit, is_train=True)\n",
    "    #    val_loss,   val_acc,   val_auprc   = run_epoch(model,   val_ld,   None, crit, is_train=False)\n",
    "    #\n",
    "    #    # log everything to W&B\n",
    "    #    wandb.log({\n",
    "    #        \"train/loss\": train_loss,\n",
    "    #        \"train/acc\":  train_acc,\n",
    "    #        \"train/auprc\":train_auprc,\n",
    "    #        \"val/loss\":   val_loss,\n",
    "    #        \"val/acc\":    val_acc,\n",
    "    #        \"val/auprc\":  val_auprc,\n",
    "    #    }, step=ep)\n",
    "    #\n",
    "    #    # early stopping on macro-AUPRC\n",
    "    #    if val_auprc > best_auprc + 1e-4:\n",
    "    #        best_auprc, patience = val_auprc, 0\n",
    "    #        torch.save(model.state_dict(), ckpt_path)\n",
    "    #    else:\n",
    "    #        patience += 1\n",
    "    #        if patience >= CFG.patience:\n",
    "    #            print(f\"Stopping early at epoch {ep}, best val AUPRC={best_auprc:.4f}\")\n",
    "    #            break\n",
    "    #\n",
    "    #    print(f\"EP{ep:02d} | \"\n",
    "    #          f\"tr loss {train_loss:.3f} acc {train_acc:.3f} AUPRC {train_auprc:.3f} | \"\n",
    "    #          f\"va loss {val_loss:.3f} acc {val_acc:.3f} AUPRC {val_auprc:.3f}\")\n",
    "    ## --- final evaluation on val & test -------------------------\n",
    "    # tau_star = evaluate(model, val_ld,   \"val\",   ckpt_path, return_tau=True)\n",
    "\n",
    "    print(\"evaluate\")\n",
    "    evaluate(\n",
    "        model,\n",
    "        test_ld,\n",
    "        \"test\",\n",
    "        ckpt_path=\"/projects/bcrv/abrown3/AppleCiDEr_Skyportal/pt/ft_head_then_full.pt\",\n",
    "        tau_per_class=None,\n",
    "    )\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d9ac3-1afe-47a1-99c6-66a700c04b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c03ab-a46c-41c8-b07c-1fe28ed9cee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envapple",
   "language": "python",
   "name": "envapple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
