{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0c34a8-1a73-4278-b137-5717cd8a3661",
   "metadata": {},
   "source": [
    "<a id='index'></a>\n",
    "\n",
    "# üçè quick clean up of old notebook with image/metadata model üçè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f2910-40f5-46bb-bbe8-d9b836355f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/projects/bcrv/abrown3/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import optuna\n",
    "from optuna.exceptions import DuplicatedStudyError\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e1a94-ea50-4f85-9dea-b401d018bc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    top_k_accuracy_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import cm as _cm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2469490-09d0-4231-8f7d-4cec9563a302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau, LinearLR\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58edb729-15f7-4b7e-8ec5-691d1bb8244f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for the pandas warnings i will continue to ignore until i can't any longer\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1800c-1a99-4e9b-8931-a1f266c84b3e",
   "metadata": {},
   "source": [
    "# Part 1: dataset, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70ff97-f4ef-475b-b385-3a2282f8223f",
   "metadata": {},
   "source": [
    "we will use the following config file (which will eventually be cleaned up) for basically everything......... \n",
    "- if you keep `'use_wandb': True,`, and use the current project please add tags `config['wandb_tags']` or `config['wandb_notes']` to say who is running the model and when! i beg of you!\n",
    "    - ex tags: I use `'wandb_tags'`: `'Delta!'` for every run that is done on Delta, other tags depnd on my mood. other useful ones are `'wandb_tags'`:`group labels`, `group SN` for class info that is easily visible without scrolling the through columns on the project page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bf9e9-c192-4feb-8025-fd7aff73a8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"project\": \"AppleCiDEr\",\n",
    "    \"config_from\": None,\n",
    "    \"random_seed\": 42,  # 42, 66, 0, 12, 123\n",
    "    \"use_wandb\": False,\n",
    "    \"save_weights\": False,\n",
    "    \"weights_path\": f'/projects/bcrv/abrown3/AppleCiDEr_Skyportal/cider_weights/multi-extra-{datetime.now().strftime(\"%Y-%m-%d-%H-%M\")}',\n",
    "    \"use_pretrain\": None,\n",
    "    \"freeze\": False,\n",
    "    \"mode\": \"all\",  # 'photo', 'spectra', ;metdata & images', 'all', 'ztf'\n",
    "    ## Data General\n",
    "    \"step\": \"type\",\n",
    "    #'classes': ['SN I','SN II', 'Cataclysmic', 'AGN', 'Tidal Disruption Event'],\n",
    "    \"classes\": [\n",
    "        \"SN Ia\",\n",
    "        \"SN Ib\",\n",
    "        \"SN Ic\",\n",
    "        \"SN II\",\n",
    "        \"SN IIP\",\n",
    "        \"SN IIn\",\n",
    "        \"Cataclysmic\",\n",
    "        \"AGN\",\n",
    "        \"Tidal Disruption Event\",\n",
    "    ],\n",
    "    \"group_labels\": True,\n",
    "    \"num_classes\": 10,\n",
    "    #'max_samples': 5500,\n",
    "    \"gpu\": 1,\n",
    "    ## Data General\n",
    "    \"preprocessed_path\": \"/work/nvme/bcrv/abrown3/preprocessed_data/data_multi/day10\",\n",
    "    # for ALERTS\n",
    "    \"train_csv_path\": \"/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Train_vetted_7-6.csv\",\n",
    "    \"val_csv_path\": \"/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Val_vetted_7-6.csv\",\n",
    "    \"test_csv_path\": \"/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Test_vetted_7-6.csv\",\n",
    "    # for SPECTRA\n",
    "    \"spec_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "    ## personal tag for weights files in local folder\n",
    "    \"custom_weight_path\": False,\n",
    "    \"custom_weight_name\": \"-\",\n",
    "    ## only for the wandb users.....\n",
    "    \"use_notes_tags\": False,\n",
    "    \"wandb_tags\": [\"Delta!\", \"multi\"],\n",
    "    \"wandb_notes\": f\"test\",\n",
    "    ## Photometry Model üçèüçè\n",
    "    \"photo_event_path\": \"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events\",\n",
    "    \"output_dir\": \"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events\",\n",
    "    \"stats_file\": \"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events/feature_stats_day100.npz\",\n",
    "    \"horizon_days\": 10.0,  # <- fine-tuning on 50 days\n",
    "    \"sampler_balance\": False,\n",
    "    \"num_workers\": 0,\n",
    "    \"p_d_model\": 128,\n",
    "    \"p_n_heads\": 8,  # 4,\n",
    "    \"p_n_layers\": 4,  # 2,\n",
    "    \"p_dropout\": 0.30,\n",
    "    \"max_len\": 257,  # 300,#256,#128,#128,\n",
    "    #'lr' : 5e-6,\n",
    "    # 'weight_decay' : 1e-2,\n",
    "    # 'focal_gamma':2.0,\n",
    "    #'cut_time_p':None, #(.25,.25,.25,.25), #None,  # or (.25,.25,.25,.25)\n",
    "    #'p_dropout':0.1,\n",
    "    #'jitter_scale':0.10,\n",
    "    #'flux_nu':8,\n",
    "    # training schedule\n",
    "    #'epochs' :150,\n",
    "    #'patience' :30,\n",
    "    # misc\n",
    "    #'seed':42,\n",
    "    #'NUM_CLASSES':5,\n",
    "    ## Spectra Model üçèüçèüçèüçèüçè\n",
    "    # \"learning_rate\",\n",
    "    # \"weight_decay\": 1e-5,\n",
    "    # \"ema_decay\": 0.995,\n",
    "    # \"focal_loss_gamma\": 2.0,\n",
    "    # \"warmup_epochs\": 10,\n",
    "    \"T_0\": 5,\n",
    "    \"T_mult\": 1,\n",
    "    \"eta_min\": 1e-5,\n",
    "    \"start_factor\": 1e-6,\n",
    "    \"end_factor\": 1.0,\n",
    "    # \"num_workers\": 0,\n",
    "    # \"sampling\": False,\n",
    "    # \"epochs\": 100,\n",
    "    # \"optimizer\": \"AdamW\",\n",
    "    # \"patience\": 14,\n",
    "    \"train_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "    \"val_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "    \"test_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "    \"class_order\": [\"SN I\", \"SN II\", \"Cataclysmic\", \"AGN\", \"Tidal Disruption Event\"],\n",
    "    ## Metadata & Image Model üçèüçè\n",
    "    \"num_experts\": 4,\n",
    "    \"towers_hidden_dims\": 16,\n",
    "    \"towers_outdims\": 4,\n",
    "    \"embedding\": \"False\",\n",
    "    \"fusion_hidden_dims\": 128,\n",
    "    \"fusion_router_dims\": 128,\n",
    "    \"fusion_outdims\": 4,\n",
    "    \"cnn_lr\": 2,\n",
    "    \"cnn_decay\": 5e-2,\n",
    "    \"psf_lr\": 0.5,\n",
    "    \"psf_decay\": 5e-2,\n",
    "    \"mag_lr\": 2,\n",
    "    \"mag_decay\": 0.0,\n",
    "    \"lc_lr\": 2,\n",
    "    \"lc_decay\": 0.05,\n",
    "    \"spatial_lr\": 2,\n",
    "    \"spatial_decay\": 0.0,\n",
    "    \"coord_lr\": 0.5,\n",
    "    \"coord_decay\": 0.0,\n",
    "    \"nst1_lr\": 2,\n",
    "    \"nst1_decay\": 0.0,\n",
    "    \"nst2_lr\": 2,\n",
    "    \"nst2_decay\": 0.0,\n",
    "    \"fusion_lr\": 1,\n",
    "    \"fusion_decay\": 1e-2,\n",
    "    \"fusion_beta1\": 0.9,\n",
    "    \"fusion_beta2\": 0.999,\n",
    "    \"router_decay\": 0.0,\n",
    "    \"router_lr\": 1.5,\n",
    "    \"router_beta1\": 0.9,\n",
    "    \"router_beta2\": 0.999,\n",
    "    \"router_lr_2\": 1,\n",
    "    \"router_beta1_2\": 0.95,\n",
    "    \"router_beta2_2\": 0.99,\n",
    "    \"classifier_decay\": 0.0,\n",
    "    \"classifier_lr\": 2.44,\n",
    "    \"classifier_beta1\": 0.95,\n",
    "    \"classifier_beta2\": 0.99,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"eps\": 5e-10,\n",
    "    \"sched_pat\": 5,\n",
    "    \"sched_factor\": 0.4,\n",
    "    \"min_lr\": 6e-10,\n",
    "    \"weight_exp\": 1,\n",
    "    \"gamma\": 2.5,\n",
    "    \"criterion\": \"cross_entropy\",\n",
    "    \"scheduler\": \"cosine_annealing\",\n",
    "    \"t_max\": 6,\n",
    "    \"max_norm\": 5,\n",
    "    ## MultiModal Model üçèüçè\n",
    "    \"hidden_dim\": 64,\n",
    "    \"fusion\": \"avg\",  # 'avg', 'concat'\n",
    "    ## Training\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.001,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"epochs\": 5,\n",
    "    \"early_stopping_patience\": 4,\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",  # 'ExponentialLR', 'ReduceLROnPlateau'\n",
    "    \"gamma\": 0.9,  # for ExponentialLR scheduler\n",
    "    \"factor\": 0.3,  # for ReduceLROnPlateau scheduler\n",
    "    \"patience\": 3,  # for ReduceLROnPlateau scheduler\n",
    "    \"warmup\": False,\n",
    "    \"warmup_epochs\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291fc04-4e05-4f67-a746-c0b3932dc3ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_config(trial):\n",
    "    config = {\n",
    "        \"project\": \"AppleCiDEr\",\n",
    "        \"config_from\": None,\n",
    "        \"random_seed\": 42,  # 42, 66, 0, 12, 123\n",
    "        \"use_wandb\": False,\n",
    "        \"save_weights\": False,\n",
    "        \"weights_path\": f'/projects/bcrv/abrown3/AppleCiDEr_Skyportal/cider_weights/multi-extra-{datetime.now().strftime(\"%Y-%m-%d-%H-%M\")}',\n",
    "        \"use_pretrain\": None,\n",
    "        \"freeze\": False,\n",
    "        \"step\": \"type\",\n",
    "        \"classes\": [\n",
    "            \"SN Ia\",\n",
    "            \"SN Ib\",\n",
    "            \"SN Ic\",\n",
    "            \"SN II\",\n",
    "            \"SN IIP\",\n",
    "            \"SN IIn\",\n",
    "            \"Cataclysmic\",\n",
    "            \"AGN\",\n",
    "            \"Tidal Disruption Event\",\n",
    "        ],\n",
    "        \"group_labels\": True,\n",
    "        \"num_classes\": 10,\n",
    "        #'max_samples': 5500,\n",
    "        ## Data General\n",
    "        \"preprocessed_path\": \"/work/nvme/bcrv/abrown3/preprocessed_data/data_multi/day10\",\n",
    "        # for ALERTS\n",
    "        \"train_csv_path\": \"/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Train_vetted_7-6.csv\",\n",
    "        \"val_csv_path\": \"/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Val_vetted_7-6.csv\",\n",
    "        \"test_csv_path\": \"/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Test_vetted_7-6.csv\",\n",
    "        # for SPECTRA\n",
    "        \"spec_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "        #'class_weights': False,\n",
    "        #'generate_train_val_files': False,\n",
    "        ## personal tag for weights files in local folder\n",
    "        \"custom_weight_path\": False,\n",
    "        \"custom_weight_name\": \"-\",\n",
    "        ## only for the wandb users.....\n",
    "        \"use_notes_tags\": False,\n",
    "        \"wandb_tags\": [\"Delta!\"],\n",
    "        \"wandb_notes\": f\" 9 class version\",\n",
    "        ## Photometry Model üçèüçè\n",
    "        \"photo_event_path\": \"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events\",\n",
    "        \"output_dir\": \"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events\",\n",
    "        \"stats_file\": \"/work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events/feature_stats_day100.npz\",\n",
    "        \"horizon_days\": 10.0,  # <- fine-tuning on 50 days\n",
    "        #'batch_size'   :  256, #64,\n",
    "        \"sampler_balance\": False,\n",
    "        \"num_workers\": 0,\n",
    "        # model stuff\n",
    "        \"p_d_model\": 128,\n",
    "        \"p_n_heads\": 8,  # 4,\n",
    "        \"p_n_layers\": 4,  # 2,\n",
    "        \"p_dropout\": 0.30,\n",
    "        \"max_len\": 257,  # 300,#256,#128,#128,\n",
    "        #'lr' : 5e-6,\n",
    "        # 'weight_decay' : 1e-2,\n",
    "        # 'focal_gamma':2.0,\n",
    "        #'cut_time_p':None, #(.25,.25,.25,.25), #None,  # or (.25,.25,.25,.25)\n",
    "        #'p_dropout':0.1,\n",
    "        #'jitter_scale':0.10,\n",
    "        #'flux_nu':8,\n",
    "        # training schedule\n",
    "        #'epochs' :150,\n",
    "        #'patience' :30,\n",
    "        # misc\n",
    "        #'seed':42,\n",
    "        #'NUM_CLASSES':5,\n",
    "        ## Spectra Model üçèüçè\n",
    "        # \"learning_rate\",\n",
    "        # \"weight_decay\": 1e-5,\n",
    "        # \"ema_decay\": 0.995,\n",
    "        # \"focal_loss_gamma\": 2.0,\n",
    "        # \"warmup_epochs\": 10,\n",
    "        \"T_0\": 5,\n",
    "        \"T_mult\": 1,\n",
    "        \"eta_min\": 1e-5,\n",
    "        \"start_factor\": 1e-6,\n",
    "        \"end_factor\": 1.0,\n",
    "        # \"num_workers\": 0,\n",
    "        # \"sampling\": False,\n",
    "        # \"epochs\": 100,\n",
    "        # \"optimizer\": \"AdamW\",\n",
    "        # \"patience\": 14,\n",
    "        \"train_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "        \"val_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "        \"test_dir\": \"/work/nvme/bcrv/mxu11\",\n",
    "        # \"class_order\": ['SN I', 'SN II', 'Cataclysmic', 'AGN', 'Tidal Disruption Event'],\n",
    "        \"class_order\": [\n",
    "            \"SN Ia\",\n",
    "            \"SN Ib\",\n",
    "            \"SN Ic\",\n",
    "            \"SN II\",\n",
    "            \"SN IIP\",\n",
    "            \"SN IIn\",\n",
    "            \"Cataclysmic\",\n",
    "            \"AGN\",\n",
    "            \"Tidal Disruption Event\",\n",
    "        ],\n",
    "        #'s_dropout': 0.2,\n",
    "        #'s_conv_channels': [1, 64, 64, 32, 32],\n",
    "        #'s_kernel_size': 3,\n",
    "        #'s_mp_kernel_size': 4,\n",
    "        ## Metadata & Image Model üçèüçè\n",
    "        \"num_experts\": 4,\n",
    "        \"towers_hidden_dims\": 16,\n",
    "        \"towers_outdims\": 4,\n",
    "        \"embedding\": \"False\",\n",
    "        \"fusion_hidden_dims\": 128,\n",
    "        \"fusion_router_dims\": 128,\n",
    "        \"fusion_outdims\": 4,\n",
    "        \"cnn_lr\": 2,\n",
    "        \"cnn_decay\": 5e-2,\n",
    "        \"psf_lr\": 0.5,\n",
    "        \"psf_decay\": 5e-2,\n",
    "        \"mag_lr\": 2,\n",
    "        \"mag_decay\": 0.0,\n",
    "        \"lc_lr\": 2,\n",
    "        \"lc_decay\": 0.05,\n",
    "        \"spatial_lr\": 2,\n",
    "        \"spatial_decay\": 0.0,\n",
    "        \"coord_lr\": 0.5,\n",
    "        \"coord_decay\": 0.0,\n",
    "        \"nst1_lr\": 2,\n",
    "        \"nst1_decay\": 0.0,\n",
    "        \"nst2_lr\": 2,\n",
    "        \"nst2_decay\": 0.0,\n",
    "        \"fusion_lr\": 1,\n",
    "        \"fusion_decay\": 1e-2,\n",
    "        \"fusion_beta1\": 0.9,\n",
    "        \"fusion_beta2\": 0.999,\n",
    "        \"router_decay\": 0.0,\n",
    "        \"router_lr\": 1.5,\n",
    "        \"router_beta1\": 0.9,\n",
    "        \"router_beta2\": 0.999,\n",
    "        \"router_lr_2\": 1,\n",
    "        \"router_beta1_2\": 0.95,\n",
    "        \"router_beta2_2\": 0.99,\n",
    "        \"classifier_decay\": 0.0,\n",
    "        \"classifier_lr\": 2.44,\n",
    "        \"classifier_beta1\": 0.95,\n",
    "        \"classifier_beta2\": 0.99,\n",
    "        \"beta1\": 0.9,\n",
    "        \"beta2\": 0.999,\n",
    "        \"eps\": 5e-10,\n",
    "        \"sched_pat\": 5,\n",
    "        \"sched_factor\": 0.4,\n",
    "        \"min_lr\": 6e-10,\n",
    "        \"weight_exp\": 1,\n",
    "        \"gamma\": 2.5,\n",
    "        \"criterion\": \"cross_entropy\",\n",
    "        \"scheduler\": \"cosine_annealing\",\n",
    "        \"t_max\": 6,\n",
    "        \"max_norm\": 5,\n",
    "        ## MultiModal Model üçèüçè\n",
    "        \"hidden_dim\": 64,\n",
    "        \"fusion\": \"avg\",  # 'avg', 'concat'\n",
    "        ## Training\n",
    "        \"batch_size\": 32,\n",
    "        \"lr\": 0.001,\n",
    "        \"beta1\": 0.9,\n",
    "        \"beta2\": 0.999,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"epochs\": 5,\n",
    "        \"early_stopping_patience\": 4,\n",
    "        \"scheduler\": \"ReduceLROnPlateau\",  # 'ExponentialLR', 'ReduceLROnPlateau'\n",
    "        \"gamma\": 0.9,  # for ExponentialLR scheduler\n",
    "        \"factor\": 0.3,  # for ReduceLROnPlateau scheduler\n",
    "        \"patience\": 3,  # for ReduceLROnPlateau scheduler\n",
    "        \"warmup\": False,\n",
    "        \"warmup_epochs\": 10,\n",
    "    }\n",
    "\n",
    "    if STUDY_NAME.startswith(\"photo\"):\n",
    "        config[\"mode\"] = \"photo\"\n",
    "        config[\"epochs\"] = 50\n",
    "    elif STUDY_NAME.startswith(\"spectra\"):\n",
    "        config[\"mode\"] = \"spectra\"\n",
    "        config[\"epochs\"] = 50\n",
    "    elif STUDY_NAME.startswith(\"meta\"):\n",
    "        config[\"mode\"] = \"meta\"\n",
    "        config[\"epochs\"] = 50\n",
    "    elif STUDY_NAME.startswith(\"image\"):\n",
    "        config[\"mode\"] = \"image\"\n",
    "        config[\"epochs\"] = 50\n",
    "\n",
    "    elif STUDY_NAME.startswith(\"ztf\"):\n",
    "        config[\"mode\"] = \"ztf\"\n",
    "        config[\"epochs\"] = 50\n",
    "\n",
    "    elif STUDY_NAME.startswith(\"all\"):\n",
    "        config[\"mode\"] = \"all\"\n",
    "        config[\"epochs\"] = 50\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unknown study name {STUDY_NAME}\")\n",
    "\n",
    "    if config[\"mode\"] in (\"photo\", \"ztf\", \"all\"):\n",
    "        config[\"p_dropout\"] = trial.suggest_float(\"p_dropout\", 0.0, 0.4)\n",
    "\n",
    "    config[\"lr\"] = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    config[\"factor\"] = trial.suggest_float(\"factor\", 0.1, 1.0)\n",
    "    config[\"beta1\"] = trial.suggest_float(\"beta1\", 0.7, 0.99)\n",
    "    config[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    config[\"study_name\"] = STUDY_NAME\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01618e-4c89-4647-a945-54e4ddc375eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(\"/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Train_vetted.csv\")\n",
    "# Val = pd.read_csv('/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Val_vetted.csv')\n",
    "# Test = pd.read_csv('/projects/bcrv/abrown3/AppleCiDEr_csv/AppleCider_Test_vetted.csv')\n",
    "# Train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8d23a-9341-4457-acd9-0265c064c87f",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>\n",
    "<br>\n",
    "`CiderDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31974de8-63f7-446b-b281-4a07953f042e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CiderDataset(Dataset):\n",
    "    def __init__(self, config, split=\"train\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.split = split  #  'train', 'val', 'test'\n",
    "        self.mode = config[\"mode\"]  #  'all', 'ztf', 'photo', 'metadata & images', 'spectra'\n",
    "        self.preprocessed_path = config[\"preprocessed_path\"]\n",
    "        self.step = config[\"step\"]\n",
    "        self.random_seed = config[\"random_seed\"]  # 42, 66, 0, 12, 123\n",
    "\n",
    "        # for ALERTS\n",
    "        self.df_train = config[\"train_csv_path\"]\n",
    "        self.df_val = config[\"val_csv_path\"]\n",
    "        self.df_test = config[\"test_csv_path\"]\n",
    "        # for SPECTRA\n",
    "        self.spec_dir = config[\"spec_dir\"]\n",
    "\n",
    "        self.photo_event_path = config[\n",
    "            \"photo_event_path\"\n",
    "        ]  # /work/hdd/bcrv/ffontinelenunes/data/AppleCider/photo_events\n",
    "\n",
    "        self.group_labels = config[\"group_labels\"]\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            self.df = pd.read_csv(self.df_train)\n",
    "        elif self.split == \"val\":\n",
    "            self.df = pd.read_csv(self.df_val)\n",
    "        elif self.split == \"test\":\n",
    "            self.df = pd.read_csv(self.df_test)\n",
    "        else:\n",
    "            raise ValueError(\"Split must be either train, val, or test.\")\n",
    "\n",
    "        self._split()\n",
    "\n",
    "        # if self.group_labels:\n",
    "        #    ## create convenient mapping for label from str to int and from int to str\n",
    "        #    ## group -> SN I, SN II, CV, AGN, TDE\n",
    "        #    self.id2target = {0: 'SN I', 1: 'SN II', 2: 'Cataclysmic', 3: 'AGN', 4: 'Tidal Disruption Event'}\n",
    "        #    self.target2id = {'SN Ia': 0 , 'SN Ic': 0,  'SN Ib': 0, 'SN II': 1, 'SN IIP': 1, 'SN IIn': 1, 'SN IIb': 1, 'Cataclysmic': 2, 'AGN': 3, 'Tidal Disruption Event': 4}\n",
    "\n",
    "        self.id2target = {\n",
    "            0: \"SN Ia\",\n",
    "            1: \"SN Ib\",\n",
    "            2: \"SN Ic\",\n",
    "            3: \"SN II\",\n",
    "            4: \"SN IIP\",\n",
    "            5: \"SN IIn\",\n",
    "            6: \"Cataclysmic\",\n",
    "            7: \"AGN\",\n",
    "            8: \"Tidal Disruption Event\",\n",
    "        }\n",
    "        self.target2id = {v: k for k, v in self.id2target.items()}\n",
    "        self.num_classes = len(self.target2id)\n",
    "\n",
    "    def _split(self):\n",
    "        \"\"\"sort train, val,test based on df\"\"\"\n",
    "        # this means that you can optionally use multiple alerts or not..\n",
    "        # doesn't change much except your dataframe would have one row per object\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            self.df = pd.read_csv(self.df_train)\n",
    "        elif self.split == \"val\":\n",
    "            self.df = pd.read_csv(self.df_val)\n",
    "        elif self.split == \"test\":\n",
    "            self.df = pd.read_csv(self.df_test)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Split must be either train, val, or test.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        el = self.df.iloc[index]  #  get df row for object\n",
    "        target = self.target2id[el[self.step]]  #  get object type, make str label int\n",
    "\n",
    "        obj_id, file = el[\"name\"], el[\"file\"]\n",
    "\n",
    "        file_path = os.path.join(self.preprocessed_path, file)  #  get object alert file name from df\n",
    "        sample = np.load(file_path, allow_pickle=True).item()  #  load object alert file: .npy\n",
    "\n",
    "        try:\n",
    "            # ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ Photometry ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ\n",
    "            event_path = os.path.join(self.photo_event_path, self.split)\n",
    "            photo_event = np.load(os.path.join(event_path, f\"{obj_id}.npz\"))\n",
    "            photometry = photo_event[\"data\"] if isinstance(photo_event, np.lib.npyio.NpzFile) else photo_event\n",
    "            event_mjd = el[\"alert mjd\"]\n",
    "\n",
    "            # new cut to photo event\n",
    "            photometry = photometry[photometry[:, 0] <= event_mjd]\n",
    "\n",
    "            _BAND_OH = np.eye(3, dtype=np.float32)\n",
    "            dt = np.log1p(photometry[:, 0])\n",
    "            dt_prev = np.log1p(photometry[:, 1])\n",
    "            logf, logfe = photometry[:, 3], photometry[:, 4]\n",
    "            oh = _BAND_OH[photometry[:, 2].astype(np.int64)]\n",
    "            vec4 = np.stack([dt, dt_prev, logf, logfe], 1)\n",
    "            photo_tensor = torch.from_numpy(np.concatenate([vec4, oh], 1))\n",
    "\n",
    "        except:\n",
    "            raise ValueError(f\"photo error! at {file}\")\n",
    "        # ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ Metadata ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ\n",
    "        metadata = sample[\"metadata norm\"]\n",
    "        metadata_tensor = torch.tensor(metadata)\n",
    "        metadata_tensor = metadata_tensor.to(torch.float32)\n",
    "\n",
    "        # ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ Images ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ\n",
    "        image_tensor = sample[\"images norm, radial distance\"]\n",
    "        # needs to be converted\n",
    "        image_tensor = image_tensor.to(torch.float32)\n",
    "\n",
    "        # ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ Spectra ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ\n",
    "        obj_spec_file = os.path.join(self.spec_dir, f\"{obj_id}.npy\")\n",
    "        flux = np.load(obj_spec_file, allow_pickle=True)\n",
    "        spectra_tensor = torch.tensor(flux, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return photo_tensor, metadata_tensor, image_tensor, spectra_tensor, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4a48c-395e-4991-9530-1e5ef83b301a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ = CiderDataset(config, split=\"train\")\n",
    "val_ = CiderDataset(config, split=\"val\")\n",
    "test_ = CiderDataset(config, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed060b4-7c3a-4378-b622-74ea454bc13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "photo, metadata, images, spectra, labels = train_[0]\n",
    "\n",
    "print(\"photometry: \", photo.shape)\n",
    "print(\"metadata: \", metadata.shape)\n",
    "print(\"images: \", images.shape)\n",
    "print(\"spectra: \", spectra.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d68a9b9-8464-4bbe-9afa-141cee3606a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "train_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149360c3-f306-4950-a3f4-f3e018ddfedd",
   "metadata": {},
   "source": [
    "<a id='loader'></a>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b30eac39-e3d2-4f5c-93bd-2389407c35bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "from AppleCiDEr_Skyportal.AppleCider.models.Time2Vec import collate\n",
    "\n",
    "train_ld = DataLoader(train_, batch_size=24, shuffle=True, num_workers = 0,\n",
    "                         collate_fn=collate)#, pin_memory=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56f5d945-7b49-4138-99ef-de8361cb773b",
   "metadata": {
    "tags": []
   },
   "source": [
    "next(iter(train_ld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3e770-c8ae-48e5-b7dc-51b9edb94a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "photo, photo_mask, metadata, images, spectra, labels = next(iter(train_ld))\n",
    "\n",
    "\n",
    "print(\"photometry:      \", photo.shape)\n",
    "print(\"photometry mask: \", photo_mask.shape)\n",
    "print(\"metadata:        \", metadata.shape)\n",
    "print(\"images:          \", images.shape)\n",
    "print(\"spectra:         \", spectra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d16b9-7952-42e9-a1d6-f1d93e74c77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(photo.dtype)\n",
    "print(photo_mask.dtype)\n",
    "print(metadata.dtype)\n",
    "print(images.dtype)\n",
    "print(spectra.dtype)\n",
    "print(labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390dbb9c-504e-4265-a265-5254d1cae8b5",
   "metadata": {},
   "source": [
    "# our models....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd07a1f-564c-49cd-b64b-578c05ae43aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='meta'></a>\n",
    "### img, meta: XastroMiNN\n",
    "<br>\n",
    "\n",
    "<small><i>[back to index](#index)</i></small>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "925ba24d-2c6c-476e-8b5c-07ba0686d1dd",
   "metadata": {},
   "source": [
    "'/projects/bcrv/abrown3/AppleCiDEr_Skyportal/AppleCider/models/XastroMiNN.py'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cc894cb-dd67-473e-bc06-4a4f3e916f5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "meta_config = {\n",
    "        \n",
    "        \"mode\": 'trial',\n",
    "        \"fusion trial\": True,\n",
    "        \"classifier trial\": True,\n",
    "        \"basic trial\":True,\n",
    "        \n",
    "        \"dataset classes\":[['SN Ia','SN Ic','SN Ib'],[ 'SN IIP', 'SN IIn','SN II'], ['Cataclysmic'], ['AGN'], ['Tidal Disruption Event']],\n",
    "        \"classes\": ['SN I', 'SN II', 'Cataclysmic', 'AGN','Tidal Disruption Event'],\n",
    "        \n",
    "        \"gpu\":1,\n",
    "        \"embed_freq\": 7,\n",
    "        \n",
    "        \"learning_rate\":1.6e-4, \n",
    "        \n",
    "        #\"epochs\":50,\n",
    "        \"patience\":3,\n",
    "        \"batch_size\":128,\n",
    "        \"seed\":135,\n",
    "        \"loader_seed\":125,\n",
    "        \n",
    "        \"num_experts\":4,\n",
    "        \"towers_hidden_dims\":16,\n",
    "        \"towers_outdims\":4,\n",
    "        \"embedding\":\"False\",\n",
    "        \n",
    "        \"fusion_hidden_dims\":128,\n",
    "        \"fusion_router_dims\":128,\n",
    "        \"fusion_outdims\":4,\n",
    "        \n",
    "        \"cnn_lr\":2,\n",
    "        \"cnn_decay\":5e-2,\n",
    "        \"psf_lr\":0.5,\n",
    "        \"psf_decay\":5e-2,\n",
    "        \"mag_lr\": 2,\n",
    "        \"mag_decay\": 0.0,\n",
    "        \n",
    "        \"lc_lr\": 2,\n",
    "        \"lc_decay\": 0.05,\n",
    "        \"spatial_lr\":2,\n",
    "        \"spatial_decay\":0.0,\n",
    "        \n",
    "        \"coord_lr\": 0.5,\n",
    "        \"coord_decay\": 0.0,\n",
    "        \n",
    "        \"nst1_lr\":2,\n",
    "        \"nst1_decay\":0.0,\n",
    "        \"nst2_lr\":2,\n",
    "        \"nst2_decay\":0.0,\n",
    "        \n",
    "        \"fusion_lr\":1,\n",
    "        \"fusion_decay\":1e-2,\n",
    "        \"fusion_beta1\": 0.9,\n",
    "        \"fusion_beta2\": 0.999,\n",
    "        \n",
    "        \"router_decay\":0.0,\n",
    "        \"router_lr\":1.5,\n",
    "        \"router_beta1\":0.9,\n",
    "        \"router_beta2\":0.999,\n",
    "        \"router_lr_2\":1,\n",
    "        \"router_beta1_2\":0.95,\n",
    "        \"router_beta2_2\":0.99,\n",
    "        \n",
    "        \"classifier_decay\": 0.0,\n",
    "        \"classifier_lr\":2.44,\n",
    "        \"classifier_beta1\":0.95,\n",
    "        \"classifier_beta2\":0.99,\n",
    "        \n",
    "        \"beta1\":0.9,\n",
    "        \"beta2\":0.999,\n",
    "        \"eps\":5e-10,\n",
    "        \n",
    "        \"sched_pat\":5,\n",
    "        \"sched_factor\":0.4,\n",
    "        \n",
    "        \"min_lr\":6e-10,\n",
    "        \n",
    "        \"weight_exp\":1,\n",
    "        \"gamma\":2.5,\n",
    "        \n",
    "        \"criterion\": \"cross_entropy\",\n",
    "        \"scheduler\": \"cosine_annealing\", \n",
    "        \"t_max\": 6,\n",
    "        \"max_norm\":5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d18868-de92-4da8-87c8-90c8aeb83534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# horrible import, fix later\n",
    "from AppleCiDEr_Skyportal.AppleCider.models.XastroMiNN import ResidualTowerBlock, SplitHeadConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b70d77-8416-4379-9b3e-fe1a7c9e5a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "class XastroMiNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Image and Metadata transient classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=5,\n",
    "        num_mlp_experts=4,\n",
    "        towers_hidden_dims=16,\n",
    "        towers_outdims=32,\n",
    "        fusion_hidden_dims=128,\n",
    "        fusion_router_dims=128,\n",
    "        fusion_outdims=32,\n",
    "        config=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.classification = True if config['mode'] == 'metdata & images' else False\n",
    "\n",
    "        self.has_image = True  # Flag for image availability\n",
    "        self.num_classes = num_classes\n",
    "        self.towers_hidden_dims = towers_hidden_dims\n",
    "        self.towers_outdims = towers_outdims\n",
    "\n",
    "        self.fusion_hidden_dims = fusion_hidden_dims  # was 1024\n",
    "        self.fusion_router_dims = fusion_router_dims  # was 256\n",
    "        self.fusion_outdims = fusion_outdims\n",
    "\n",
    "        # ===== Metadata Processing Towers =====\n",
    "        # Each tower processes specific metadata features\n",
    "        # PSF quality features tower\n",
    "        self.psf_tower = ResidualTowerBlock(2, self.towers_hidden_dims, towers_outdims)\n",
    "\n",
    "        # Magnitude features tower\n",
    "        self.mag_tower = ResidualTowerBlock(7, self.towers_hidden_dims * 2, towers_outdims)\n",
    "\n",
    "        # LC features tower\n",
    "        self.lc_tower = ResidualTowerBlock(12, self.towers_hidden_dims * 3, towers_outdims)\n",
    "\n",
    "        # Spatial features tower (distpsnr1, distpsnr2, nmtchps)\n",
    "        self.spatial_tower = ResidualTowerBlock(3, self.towers_hidden_dims, towers_outdims)\n",
    "\n",
    "        # Nearest source features tower 1 (sgscore1, distpsnr1)\n",
    "        self.nst1_tower = ResidualTowerBlock(2, self.towers_hidden_dims, fusion_outdims)\n",
    "        # self.mega_tower = ResidualTowerBlock(7, 64, self.towers_outdims)\n",
    "        # Nearest source features tower 2 (sgscore2, distpsnr2)\n",
    "        self.nst2_tower = ResidualTowerBlock(2, self.towers_hidden_dims, fusion_outdims)\n",
    "\n",
    "        self.coord_tower = ResidualTowerBlock(2, self.towers_hidden_dims, fusion_outdims)\n",
    "\n",
    "        self.mega_tower = ResidualTowerBlock(19, 128, towers_outdims)\n",
    "\n",
    "        self.image_tower = SplitHeadConvNeXt(\n",
    "            pretrained=False,  # or False if training from scratch\n",
    "            in_chans=4,  # Critical: override default 3-channel input\n",
    "            outdims=towers_outdims,  # Your task's number of classes\n",
    "        ).to(device)\n",
    "\n",
    "        fusion_dims = 6 * towers_outdims + 3 * fusion_outdims\n",
    "        # ===== Modality Fusion MoE =====\n",
    "        # Combines features from all towers (4 metadata + image)\n",
    "        self.fusion_experts = nn.ModuleList(\n",
    "            [ResidualTowerBlock(fusion_dims, fusion_hidden_dims, 5) for _ in range(num_mlp_experts)]\n",
    "        )\n",
    "\n",
    "        num_experts = num_mlp_experts\n",
    "        self.fusion_router = nn.Sequential(\n",
    "            nn.Linear(fusion_dims, fusion_dims // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fusion_dims // 2, num_experts),\n",
    "            # nn.Softmax(dim=-1)  # each expert gets independent [0,1] weight\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, metadata, image):\n",
    "        \"\"\"Processes input metadata and optional image data through specialized towers,\n",
    "        combines features using a Mixture of Experts (MoE) approach, and returns\n",
    "        classification logits with expert weighting information.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        metadata : torch.Tensor\n",
    "            Input metadata tensor of shape (batch_size, num_metadata_features).\n",
    "            Expected to contain 24 metadata features (indices 0-23).\n",
    "        image : torch.Tensor, optional\n",
    "            Input image tensor of shape (batch_size, channels, height, width).\n",
    "            If None, image features will be zero-initialized.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary containing:\n",
    "            - 'logits': torch.Tensor\n",
    "                Output classification logits of shape (batch_size, num_classes)\n",
    "            - 'expert_weights': torch.Tensor\n",
    "                Raw fusion weights for all experts\n",
    "            - 'fusion_weights': torch.Tensor\n",
    "                Same as expert_weights (maintained for compatibility)\"\"\"\n",
    "\n",
    "        # Process all metadata features through respective towers\n",
    "        psf_feats = self.psf_tower(metadata[:, [5, 14]])  # PSF features\n",
    "        lc_feats = self.lc_tower(metadata[:, [6, 9, 10, 13, 15, 17, 18, 19, 20, 21, 22, 23]])\n",
    "        mag_feats = self.mag_tower(metadata[:, [6, 9, 10, 13, 15, 17, 18]])\n",
    "\n",
    "        spatial_feats = self.spatial_tower(metadata[:, [2, 3, 4]])  # Spatial features\n",
    "        nsta = self.nst1_tower(metadata[:, [0, 2]])  # Nearest source A features\n",
    "        nstb = self.nst2_tower(metadata[:, [1, 3]])  # Nearest source B features\n",
    "        coord_feats = self.coord_tower(metadata[:, [7, 8]])\n",
    "        megatower = self.mega_tower(\n",
    "            metadata[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]]\n",
    "        )\n",
    "\n",
    "        # Process image if available (zeros otherwise)\n",
    "        image_feats = self.image_tower(image) if image is not None else torch.zeros_like(nsta)\n",
    "\n",
    "        # Concatenate all features for fusion\n",
    "        all_feats = torch.cat(\n",
    "            [nsta, nstb, spatial_feats, psf_feats, mag_feats, coord_feats, megatower, image_feats, lc_feats],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        # Fusion MoE - combine features from all modalities\n",
    "        fusion_weights = self.fusion_router(all_feats)\n",
    "\n",
    "        moe_output = torch.zeros(metadata.size(0), 5, device=\"cuda\")  # ,device=metadata.to(device))\n",
    "\n",
    "        topk_weights, topk_indices = torch.topk(fusion_weights, k=2, dim=-1)  # [B, k]\n",
    "\n",
    "        # Process only through selected experts\n",
    "        for expert_idx, expert in enumerate(self.fusion_experts):\n",
    "            # Mask for samples where this expert is in top-k\n",
    "            expert_mask = (topk_indices == expert_idx).any(dim=-1)  # [B]   # 'ResidualTowerBlock'\n",
    "\n",
    "            if expert_mask.any():\n",
    "                # Get weights for this expert [M] where M=sum(expert_mask)\n",
    "                weights = topk_weights[expert_mask, (topk_indices[expert_mask] == expert_idx).nonzero()[:, 1]]\n",
    "                # Compute expert output only for relevant samples\n",
    "                expert_out = expert(all_feats[expert_mask])  # [M, num_classes]\n",
    "                # Weighted contribution\n",
    "                moe_output[expert_mask] += weights.unsqueeze(-1) * expert_out\n",
    "\n",
    "        return moe_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999fcb6c-2d27-4d1c-b5b9-9d720f645f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# meta_model_path = '/projects/bcrv/abrown3/jobs/models_img_meta/best_model135_42dlletn.pth'\n",
    "# model_obj = torch.load(meta_model_path, weights_only = False)\n",
    "# model_obj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478efa2-2ee9-417f-b656-8c2f8f44e249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XastroMiNN_model = XastroMiNN(\n",
    "    num_classes=5,\n",
    "    num_mlp_experts=meta_config[\"num_experts\"],\n",
    "    towers_hidden_dims=meta_config[\"towers_hidden_dims\"],\n",
    "    towers_outdims=meta_config[\"towers_outdims\"],\n",
    "    fusion_hidden_dims=meta_config[\"fusion_hidden_dims\"],\n",
    "    fusion_router_dims=meta_config[\"fusion_router_dims\"],\n",
    "    fusion_outdims=meta_config[\"fusion_outdims\"],\n",
    "    config=config,\n",
    ").to(device)\n",
    "\n",
    "XastroMiNN_model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3d25c36-f1aa-465c-94f9-30729909a887",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = XastroMiNN()\n",
    "model.load_state_dict(torch.load(meta_model_path), strict=False)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envapple",
   "language": "python",
   "name": "envapple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
