{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199e6641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    }
   ],
   "source": [
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4304d835-da03-4fae-b0fe-c3e894ee17a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbranton/.virtualenvs/applecider/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Cannot find default_config.toml for torch.optim.Adam.\n",
      "Runtime config contains key or section 'train' which has no default defined. All configuration keys and sections must be defined in /Users/dbranton/lincc/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'infer' which has no default defined. All configuration keys and sections must be defined in /Users/dbranton/lincc/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'PhotoEventsDataset' which has no default defined. All configuration keys and sections must be defined in /Users/dbranton/lincc/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-11-12 10:46:24,819 hyrax.prepare:INFO] Finished Prepare\n"
     ]
    }
   ],
   "source": [
    "from hyrax import Hyrax\n",
    "\n",
    "toml_path = \"/Users/dbranton/lincc/incubators/applecider/notebooks/testing/baselinecls_testing_runtime_config.toml\"\n",
    "h = Hyrax(config_file=toml_path)\n",
    "\"\"\"\n",
    "h.config[\"model_inputs\"] = {\n",
    "    \"data\": {\n",
    "        \"dataset_class\": \"AppleCider.models.hyrax_models.photo_dataset.PhotoEventsDataset\",\n",
    "        \"data_location\": \"/Users/dbranton/lincc/incubators/photo_events/train/\",\n",
    "        \"fields\": [\"photometry\", \"label\", \"stats\"],\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "dataset = h.prepare()\n",
    "\n",
    "#h.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dd5c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-12 10:36:27,248 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining model:\u001b[0m HyraxBaselineCLS\n",
      "[2025-11-12 10:36:27,249 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining dataset(s):\u001b[0m\n",
      "{'train': Name: data (primary dataset)\n",
      "  Dataset class: AppleCider.models.hyrax_models.photo_dataset.PhotoEventsDataset\n",
      "  Data location: /Users/dbranton/lincc/incubators/photo_events/train/\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: photometry, label, mean, std\n",
      ", 'infer': Name: data (primary dataset)\n",
      "  Dataset class: AppleCider.models.hyrax_models.photo_dataset.PhotoEventsDataset\n",
      "  Data location: /Users/dbranton/lincc/incubators/photo_events/test/\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: photometry, label, mean, std\n",
      "}\n",
      "2025-11-12 10:36:27,263 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x16bc3a660>, 'batch_size': 5, 'shuffle': False, 'collate_fn': <function collate at 0x168bd3ec0>, 'pin_memory': False}\n",
      "2025-11-12 10:36:27,264 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x16bc3a690>, 'batch_size': 5, 'shuffle': False, 'collate_fn': <function collate at 0x168bd3ec0>, 'pin_memory': False}\n",
      "/Users/dbranton/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/handlers/tqdm_logger.py:127: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2025/11/12 10:36:27 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/11/12 10:36:27 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8de796cec27452183f5fb9092f4300b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 1/1533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbranton/.virtualenvs/applecider/lib/python3.12/site-packages/torch/nn/modules/transformer.py:467: UserWarning: The operator 'aten::_nested_tensor_from_mask_left_aligned' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:15.)\n",
      "  ) and not torch._nested_tensor_from_mask_left_aligned(\n",
      "[2025-11-12 10:44:10,349 hyrax.pytorch_ignite:INFO] Total training time: 462.95[s]\n",
      "2025/11/12 10:44:10 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/11/12 10:44:10 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[2025-11-12 10:44:10,396 hyrax.verbs.train:INFO] Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyraxBaselineCLS(\n",
       "  (in_proj): Linear(in_features=7, out_features=128, bias=True)\n",
       "  (time2vec): Time2Vec()\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (criterion): FocalLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e18d40-e804-46af-9a77-751f0287d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-12 10:46:29,704 hyrax.verbs.infer:INFO] \u001b[1m\u001b[30m\u001b[42mInference model:\u001b[0m HyraxBaselineCLS\n",
      "[2025-11-12 10:46:29,704 hyrax.verbs.infer:INFO] \u001b[1m\u001b[30m\u001b[42mInference dataset(s):\u001b[0m\n",
      "{'train': Name: data (primary dataset)\n",
      "  Dataset class: AppleCider.models.hyrax_models.photo_dataset.PhotoEventsDataset\n",
      "  Data location: /Users/dbranton/lincc/incubators/photo_events/train/\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: photometry, label, mean, std\n",
      ", 'infer': Name: data (primary dataset)\n",
      "  Dataset class: AppleCider.models.hyrax_models.photo_dataset.PhotoEventsDataset\n",
      "  Data location: /Users/dbranton/lincc/incubators/photo_events/test/\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: photometry, label, mean, std\n",
      "}\n",
      "2025-11-12 10:46:29,720 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': None, 'batch_size': 5, 'shuffle': False, 'collate_fn': <function collate at 0x1689d3e20>, 'pin_memory': False}\n",
      "[2025-11-12 10:46:29,747 hyrax.verbs.infer:INFO] Saving inference results at: /Users/dbranton/lincc/incubators/applecider/notebooks/testing/results/20251112-104629-infer-_N7G\n",
      "/Users/dbranton/.virtualenvs/applecider/lib/python3.12/site-packages/ignite/handlers/tqdm_logger.py:127: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/Users/dbranton/.virtualenvs/applecider/lib/python3.12/site-packages/torch/nn/modules/transformer.py:467: UserWarning: The operator 'aten::_nested_tensor_from_mask_left_aligned' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:15.)\n",
      "  ) and not torch._nested_tensor_from_mask_left_aligned(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90387a0fc8d64e9ba4f4f4f425847ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 1/548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-12 10:47:08,377 hyrax.pytorch_ignite:INFO] Total evaluation time: 38.58[s]\n",
      "[2025-11-12 10:47:08,390 hyrax.verbs.infer:INFO] Inference Complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hyrax.data_sets.inference_dataset.InferenceDataSet at 0x16a8945f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578c31d-71c5-4d8b-8bfd-b8bd38599e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
