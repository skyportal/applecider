{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4304d835-da03-4fae-b0fe-c3e894ee17a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drew/opt/miniconda3/envs/applecider/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Cannot find default_config.toml for torch.optim.Adam.\n",
      "Runtime config contains key or section 'HyraxBaselineCLS' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'lr' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'train' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'validate' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'infer' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'PhotoEventsDataset' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "Runtime config contains key or section 'applecider.datasets.photo_dataset.PhotoEventsDataset' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:51,235 hyrax.config_utils:WARNING] Cannot find default_config.toml for torch.nn.CrossEntropyLoss.\n",
      "[2025-12-15 15:29:51,235 hyrax.config_utils:WARNING] Cannot find default_config.toml for torch.optim.Adam.\n",
      "[2025-12-15 15:29:54,361 hyrax.config_utils:WARNING] Cannot find default_config.toml for umap.UMAP.\n",
      "[2025-12-15 15:29:54,362 hyrax.config_utils:INFO] Merging external default config from /Users/drew/code/applecider/src/applecider/default_config.toml\n",
      "[2025-12-15 15:29:56,372 hyrax.prepare:INFO] Finished Prepare\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "from hyrax import Hyrax\n",
    "\n",
    "toml_path = \"./baselinecls_testing_runtime_config.toml\"\n",
    "h = Hyrax(config_file=toml_path)\n",
    "h.set_config(\"data_set.PhotoEventsDataset.use_oversampling\", True)\n",
    "dataset = h.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "manifest_df = pd.read_csv(\"/Users/dbranton/lincc/incubators/photo_events/manifest_train.csv\")\n",
    "\n",
    "taxonomy_mapper = {0: 0,  # SN Ia -> SNI\n",
    "                                1: 0,  # SN Ib -> SNI\n",
    "                                2: 0,  # SN Ic -> SNI\n",
    "                                3: 1,  # SN II -> SNII\n",
    "                                4: 1,  # SN IIP -> SNII\n",
    "                                5: 1,  # SN IIn -> SNII\n",
    "                                6: 1,  # SN IIb -> SNII\n",
    "                                7: 2,  # Cataclysmic -> CV\n",
    "                                8: 3,  # AGN -> AGN\n",
    "                                9: 4,  # Tidal Disruption Event -> TDE\n",
    "                                }\n",
    "manifest_df.sort_values(\"obj_id\", inplace=True)\n",
    "\n",
    "for i in range(10):\n",
    "    if dataset['train'][i]['data']['label'] != taxonomy_mapper[manifest_df.iloc[i].label]:\n",
    "        print(f\"{dataset['train'][i]['object_id']}, {dataset['train'][i]['data']['label']}, {taxonomy_mapper[manifest_df.iloc[i].label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_df.query(\"obj_id == 'ZTF19aavnwzv'\").iloc[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(dataset[\"train\"])):\n",
    "    if dataset[\"train\"][i][\"data\"][\"label\"] == 4:\n",
    "        count += 1\n",
    "print(count/len(dataset[\"train\"]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].prepped_datasets[\"data\"].additional_samples_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741bdbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0][\"data\"][\"photometry\"][:, 4:7][20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40888a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"infer\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5670ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"infer\"].prepped_datasets[\"data\"].manifest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd5c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.config['train']['epochs'] = 1\n",
    "h.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf60c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ds = h.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes for each of the inference results\n",
    "#! Note that we need to apply softmax to the output tensors to get probabilities\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "res_list = []\n",
    "\n",
    "for i in range(32):\n",
    "    a = np.load(f\"/home/drew/code/applecider/docs/pre_executed/testing/results/20251124-150917-infer-LuHy/batch_{i}.npy\")\n",
    "\n",
    "    for i in a:\n",
    "        max_ind = np.argmax(F.softmax(torch.as_tensor(i['tensor']), dim=0).numpy())\n",
    "        res_list.append((str(i['id']), int(max_ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6167ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the known classes for each of the inference results\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "manifest_df = pd.read_csv(\"../../../data/photo_events/manifest_test.csv\")\n",
    "\n",
    "taxonomy_mapper = {0: 0,  # SN Ia -> SNI\n",
    "                                1: 0,  # SN Ib -> SNI\n",
    "                                2: 0,  # SN Ic -> SNI\n",
    "                                3: 1,  # SN II -> SNII\n",
    "                                4: 1,  # SN IIP -> SNII\n",
    "                                5: 1,  # SN IIn -> SNII\n",
    "                                6: 1,  # SN IIb -> SNII\n",
    "                                7: 2,  # Cataclysmic -> CV\n",
    "                                8: 3,  # AGN -> AGN\n",
    "                                9: 4,  # Tidal Disruption Event -> TDE\n",
    "                                }\n",
    "\n",
    "pred_class = []\n",
    "real_class = []\n",
    "for id, pred in res_list:\n",
    "    pred_class.append(pred)\n",
    "    row = manifest_df[manifest_df[\"obj_id\"] == id]\n",
    "    real_class.append(taxonomy_mapper[row.iloc[0].label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ed1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(real_class, pred_class)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8249e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-15 15:29:56,529 hyrax.config_utils:WARNING] Cannot find default_config.toml for torch.nn.CrossEntropyLoss.\n",
      "[2025-12-15 15:29:56,529 hyrax.config_utils:WARNING] Cannot find default_config.toml for torch.optim.Adam.\n",
      "[2025-12-15 15:29:56,530 hyrax.config_utils:WARNING] Cannot find default_config.toml for umap.UMAP.\n",
      "[2025-12-15 15:29:56,531 hyrax.config_utils:INFO] Merging external default config from /Users/drew/code/applecider/src/applecider/default_config.toml\n",
      "[2025-12-15 15:29:56,547 hyrax.config_utils:WARNING] Runtime config contains key or section 'HyraxBaselineCLS' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:56,548 hyrax.config_utils:WARNING] Runtime config contains key or section 'lr' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:56,549 hyrax.config_utils:WARNING] Runtime config contains key or section 'train' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:56,549 hyrax.config_utils:WARNING] Runtime config contains key or section 'validate' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:56,549 hyrax.config_utils:WARNING] Runtime config contains key or section 'infer' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:56,550 hyrax.config_utils:WARNING] Runtime config contains key or section 'PhotoEventsDataset' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:56,550 hyrax.config_utils:WARNING] Runtime config contains key or section 'applecider.datasets.photo_dataset.PhotoEventsDataset' which has no default defined. All configuration keys and sections must be defined in /Users/drew/code/hyrax/src/hyrax/hyrax_default_config.toml\n",
      "[2025-12-15 15:29:56,959 hyrax.models.model_registry:WARNING] Both model and config define an optimizer. Hyrax will use self.optimizer defined in the model.\n",
      "[2025-12-15 15:29:56,959 hyrax.models.model_registry:INFO] Using self.optimizer defined in model: torch.optim.adam.Adam\n",
      "[2025-12-15 15:29:56,960 hyrax.models.model_registry:WARNING] Both model and config define a criterion. Hyrax will use self.criterion defined in the model.\n",
      "[2025-12-15 15:29:56,960 hyrax.models.model_registry:INFO] Using self.criterion defined in model: applecider.models.HyraxBaselineCLS.FocalLoss\n",
      "2025-12-15 15:29:56,998 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': None, 'batch_size': 128, 'shuffle': False, 'collate_fn': <bound method DataProvider.collate of Name: data (primary dataset)\n",
      "  Dataset class: applecider.datasets.photo_dataset.PhotoEventsDataset\n",
      "  Data location: ../../../data/photo_events/test/\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: photometry, mean, std\n",
      "  Dataset config:\n",
      "    manifest_path: ../../../data/photo_events/manifest_test.csv\n",
      ">, 'pin_memory': False}\n",
      "/Users/drew/opt/miniconda3/envs/applecider/lib/python3.12/site-packages/torch/onnx/utils.py:636: UserWarning: ONNX Preprocess - Removing mutation from node aten::masked_fill_ on block input: 'mask'. This changes graph semantics. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:353.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n"
     ]
    }
   ],
   "source": [
    "h.to_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254fb651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input_1 for the following indices\n index: 1 Got: 139 Expected: 164\n Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgument\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hyrax/src/hyrax/verbs/engine.py:126\u001b[39m, in \u001b[36mEngine.run\u001b[39m\u001b[34m(self, model_directory)\u001b[39m\n\u001b[32m    123\u001b[39m     ort_inputs = {ort_session.get_inputs()[\u001b[32m0\u001b[39m].name: prepared_batch}\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Run the ONNX model with the prepared batch as input\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m onnx_results = \u001b[43mort_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mort_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# ~ Finally, we persist the results of inference.\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# For now, collated_batch will always have an \"object_id\" key that\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# is a list of strings. However, we should move to a state where the\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# object ids are taken from the primary dataset's \"primary_id_field\",\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# which will contain the required data - then remove the \"object_id\" key.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mobject_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m collated_batch:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/applecider/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:275\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, output_names, input_feed, run_options)\u001b[39m\n\u001b[32m    273\u001b[39m     output_names = [output.name \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._outputs_meta]\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m C.EPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_fallback:\n",
      "\u001b[31mInvalidArgument\u001b[39m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input_1 for the following indices\n index: 1 Got: 139 Expected: 164\n Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "source": [
    "h.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad352fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applecider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
